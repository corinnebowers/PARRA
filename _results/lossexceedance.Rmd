---
title: "Untitled"
author: "Corinne"
date: "4/14/2021"
output:
  html_document:
    toc: true 
    toc_float: true
    #toc_depth: 3  
    code_folding: hide
    number_sections: true 
    theme: spacelab   #https://www.datadreaming.org/post/r-markdown-theme-gallery/
    highlight: tango  #https://www.garrickadenbuie.com/blog/pandoc-syntax-highlighting-examples/
---

The purpose of this script is to ...

```{r setup, include = FALSE}
knitr::opts_knit$set(root.dir = 'D:/1-PARRA/')
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

```

```{r}
## setup information
source('_data/setup.R')
source('_data/plots.R')

## set random seed for reproducibility
set.seed(7395)

## load files
load('_data/catalog/catalog.Rdata')
load('_data/aoi/aoi.Rdata')

```


# Compute full loss histogram

## Identify case study storm
```{r}
casestudy <- catalog %>% filter(start_day == ymd('2019-02-25'))
print(casestudy)

```

go to Sherlock and run for this case study

## plot real loss vs. simulated loss distribution
```{r}
load('_results/event_2019/prcp4/DV.Rdata')
plot_loss_sim <- function(year, loss.est) {
  g <- loss.sim %>% 
    filter(n.AR == 1) %>% 
    # right_join(data.frame(n.precip = 1:1e4), by = 'n.precip') %>% 
    # mutate(loss = case_when(is.na(loss)~0, TRUE~loss)) %>% 
    ggplot() + 
    geom_histogram(aes(x = loss, y = ..density..), color = 'black', fill = 'grey90', 
                   bins = sqrt(nrow(loss.sim)), boundary = 0, size = 0.25) + 
    geom_vline(xintercept = loss.est, linetype = 'dashed') + 
    annotate(geom = 'text', 
      x = loss.est - 8e6, y = 1.9e-8, angle = 90,
      label = '2019 Observed', family = 'Segoe UI', size = 8/.pt) +
    scale_x_origin('Loss Estimate ($M)', 
      labels = comma_format(scale = 1e-6, accuracy = 1)) + 
    scale_y_origin('Frequency of Occurrence')
  return(g)
}

# plot_loss_sim(1995, 50*(91.6/155) * 1.68e6)
# plot_loss_sim(2006, 104*(91.6/155) * 1.28e6)
# plot_loss_sim(2017, 15.2*(91.6/155) * 1.04e6)

loss.est <- 91.6e6
plot_loss_sim(2019, loss.est)
ggsave('_figures/fig09/fig09_lossdist.png', width = 8.3, height = 5, units = 'cm')

```


```{r}
## percentile
1 - (sum(loss.sim$loss > loss.est) / 1e4)

## maximum event
max(loss.sim$loss)/1e6
max(loss.sim$loss) / loss.est

## nonzero events
nrow(loss.sim)/1e4

```

## spatial distribution of loss
```{r}
load('_results/event_2019/prcp4/DV.Rdata')

## census block groups
sonoma_cbgs <- block_groups(state = 'CA', county = 'Sonoma')
sonoma_cbgs %>% 
  mutate(group = toNumber(GEOID)) %>% 
  left_join(loss.group %>% mutate(group = toNumber(group)), by = 'group') %>% 
  mutate(loss = ifelse(is.na(loss), 0, loss)) %>% 
  st_transform(6417) %>% st_crop(aoi) %>% 
  ggplot() + 
  geom_sf(data = sonoma %>% st_transform(6417), fill = 'grey90', color = 'grey60', size = 0.25) +
  geom_sf(aes(fill = loss+1), color = NA) + 
  scale_fill_scico('Block Group \nLoss Estimate', palette = 'roma', 
                   begin = 0.5, #trans = 'log10', 
                   labels = comma_format(prefix = '$')) + 
  ggnewscale::new_scale_fill() + 
  geom_sf(aes(fill = loss>0), color = NA, show.legend = FALSE) + 
  scale_fill_manual(values = c('white', NA), na.value = NA) + 
  geom_sf(data = sonoma %>% st_transform(6417), fill = NA, size = 0.25, color = 'grey60') +
  geom_sf(data = st_union(sonoma), color = 'grey50', fill = NA) + 
  geom_sf(data = aoi, fill = NA, color = 'grey40') + 
  geom_sf(data = russian %>% st_transform(6417) %>% st_crop(sonoma), size = 0.75) + 
  coord_sf(expand = FALSE) +
  theme(axis.title = element_blank(), axis.text = element_blank(), 
        axis.ticks = element_blank(), axis.line = element_blank(),
        panel.background = element_blank(), plot.background = element_blank(),
        legend.position = c(0.1, 0.275), legend.background = element_blank())
ggsave('_figures/fig09/fig09_lossmap.png', width = 6, height = 9, units = 'cm')

```

## calculate AAL for entire catalog
```{r}
load(paste0('_results/stochastic/DV.Rdata'))
loss.stochastic <- loss.sim

sum(loss.stochastic$loss)/3200/1e6

```

## estimate return period for losses 
```{r}
## Corringham et al. have 5.2 billion dollars in losses
5.2e3 / 40

```

```{r}
## return period of 2019 event
p <- sum(loss.stochastic$loss > 91.6e6)/3200
percent(p, accuracy = 0.01)
comma(1/p, accuracy = 0.01)

## expected loss due to 1-in-100 year event
loss.stochastic %>% 
  arrange(desc(loss)) %>% 
  mutate(p = (1:nrow(.))/3200) %>% 
  mutate(RP = 1/p) %>% 
  filter(p == 0.01) %>%
  mutate(loss = loss/1e6) %>% pull(loss) %>% 
  comma(prefix = '$', accuracy = 0.01)

```

## mitigated case

```{r}
## raise buildings

load('_data/lisflood/dem.Rdata')
rp100 <- raster('_sensitivity/rp100/sherlock_bestfit/results/bestfit.max', crs = projection(aoi))
# mxe <- raster('_sensitivity/rp100/sherlock_bestfit/results/bestfit.mxe', crs = projection(aoi))
# plot((dem+rp100) %>% mask(mxe))
# plot(mxe)

load('_data/buildings/buildings.Rdata')
buildings$raised_m <- unlist(unname(terra::extract(rast(rp100), st_coordinates(buildings))))
buildings %>% st_drop_geometry %>% filter(raised_m > 0) %>%
  ggplot() +
  geom_histogram(aes(x = raised_m, y = ..density..), color = 'black', fill = 'grey90',
                 boundary = 0, bins = sqrt(sum(buildings$raised_m>0))) +
  scale_x_origin('Mitigated First-Floor Elevation (m)') + 
  scale_y_origin('Frequency of Occurrence')

buildings %>% st_drop_geometry %>% filter(raised_m > 0) %>% pull(raised_m) %>% length
buildings %>% st_drop_geometry %>% filter(raised_m > 0) %>% pull(raised_m) %>% mean

```


```{r}
## check the mitigated case
load(paste0('_results/mitigated/DV.Rdata'))
loss.mitigated <- loss.sim

## plot original vs. mitigated loss exceedance curve
ggplot() + 
  geom_hline(yintercept = 1e-2, color = 'grey70', linetype = 'dashed') + 
  geom_step(data = loss.stochastic %>% arrange(desc(loss)) %>% 
               mutate(exceed = (1:nrow(.))/3200),
             aes(x = loss, y = exceed, color = 'Original'), size = 0.75) +
  geom_step(data = loss.mitigated %>% arrange(desc(loss)) %>%  
               mutate(exceed = (1:nrow(.))/3200),
             aes(x = loss, y = exceed, color = 'Mitigated'), size = 0.75) +
  scale_x_origin('Loss Estimate ($M)', breaks = seq(0, 1e9, 5e7),
                 labels = comma_format(scale = 1e-6)) + 
  scale_y_log10('Probability of Exceedance', labels = scientific) +
  scale_color_manual('Building \nElevations', values = c('black', 'grey60'),
                     breaks = c('Original', 'Mitigated')) + 
  annotation_logticks(sides = 'l') + 
  theme(legend.position = c(0.75, 0.75))
ggsave('_figures/fig10_mitigated.png', width = 8.3, height = 6, units = 'cm')


```

```{r}
# left_join(
#   loss.stochastic %>% arrange(desc(loss)) %>% 
#     transmute(exceed = (1:nrow(.))/3200, loss.stochastic = loss),
#   loss.mitigated %>% arrange(desc(loss)) %>% 
#     transmute(exceed = (1:nrow(.))/3200, loss.mitigated = loss),
#   by = 'exceed') %>% 
#   ggplot() + 
#   geom_point(aes(x = exceed, y = loss.stochastic-loss.mitigated)) + 
#   scale_x_log10() + scale_y_origin(labels = comma_format(scale = 1e-6))

```


```{r}
## calculate the mitigated AAL
sum(loss.mitigated$loss)/3200

## return period of 2019 event
p <- sum(loss.mitigated$loss > 91.6e6)/3200
percent(p, accuracy = 0.01)
comma(1/p, accuracy = 0.01)

## expected loss due to 1-in-100 year event
loss.mitigated %>% 
  arrange(desc(loss)) %>% 
  mutate(p = (1:nrow(.))/3200) %>% 
  mutate(RP = 1/p) %>% 
  filter(p == 0.01) %>%
  mutate(loss = loss/1e6) %>% pull(loss) %>% 
  comma(prefix = '$', accuracy = 0.01)

```

## new mitigation tactic
```{r}
load('_data/buildings/buildings.Rdata')
buildings <- buildings %>% rename(value.sd = acs.sd)

## get original losses by building & by simulation
load(paste0('_results/stochastic/DM.Rdata'))
id.wet <- attr(damage, 'buildings') %>% as.data.frame %>% pull(id)
buildings.wet <- buildings %>% arrange(bldg) %>% 
  filter(bldg %in% id.wet) %>% 
  st_drop_geometry
values <- map2_dbl(
  .x = buildings.wet$value, .y = buildings.wet$value.sd,
  ~rnorm(1, mean = .x, sd = .y)) %>% 
  cbind(0) %>% apply(1, max)
loss.stochastic <- damage %>% 
  lapply(function(x) {
    x %>% as.data.frame %>% 
      select(-n.inun, -n.damage, -bldg) %>% 
      sweep(1, values, '*') %>% 
      cbind(x %>% as.data.frame %>% select(n.inun, n.damage, bldg))})

## get mitigated losses by building & by simulation
load(paste0('_results/mitigated/DM.Rdata'))
id.wet <- attr(damage, 'buildings') %>% as.data.frame %>% pull(id)
buildings.wet <- buildings %>% arrange(bldg) %>% 
  filter(bldg %in% id.wet) %>% 
  st_drop_geometry
values <- map2_dbl(
  .x = buildings.wet$value, .y = buildings.wet$value.sd,
  ~rnorm(1, mean = .x, sd = .y)) %>% 
  cbind(0) %>% apply(1, max)
loss.mitigated <- damage %>% 
  lapply(function(x) {
    x %>% as.data.frame %>% 
      select(-n.inun, -n.damage, -bldg) %>% 
      sweep(1, values, '*') %>% 
      cbind(x %>% as.data.frame %>% select(n.inun, n.damage, bldg))})

## combine into one dataframe
loss.bldg <- 
  left_join(
    loss.stochastic[[1]] %>% 
      select(-n.damage, -n.inun, -bldg) %>% 
      apply(1, mean) %>% 
      cbind(loss.stochastic = ., bldg = loss.stochastic[[1]]$bldg) %>% 
      as.data.frame,
    loss.mitigated[[1]] %>% 
      select(-n.damage, -n.inun, -bldg) %>% 
      apply(1, mean) %>% 
      cbind(loss.mitigated = ., bldg = loss.mitigated[[1]]$bldg) %>% 
      as.data.frame,
    by = 'bldg') %>% 
  arrange(desc(loss.stochastic))

```


```{r}
## grab simulation tracker
simulations <- attr(damage, 'sim')

# ## elevate buildings iteratively & calculate new AAL
# start <- Sys.time()
# num_cores <- 5
# cl <- parallel::makeCluster(num_cores)
# registerDoSNOW(cl)
# pb <- txtProgressBar(min = 0, max = nrow(loss.bldg), style = 3)
# loss.bldg$new_AAL <-
#   foreach(
#     i = 1:nrow(loss.bldg), 
#     .combine = 'c', .packages = 'tidyverse', 
#     .options.snow = list(progress = function(n) setTxtProgressBar(pb, n))) %dopar% {
#       simulations$loss <- 
#         rbind(
#           loss.stochastic[[1]] %>% filter(!(bldg %in% loss.bldg$bldg[1:i])),
#           loss.mitigated[[1]] %>% filter(bldg %in% loss.bldg$bldg[1:i])) %>% 
#         select(-bldg, -n.damage, -n.inun) %>% 
#         apply(2, sum)
#       sum(simulations$loss)/3200
#     }
# stopCluster(cl)
# Sys.time() - start

load('loss.bldg.Rdata')

ggplot(loss.bldg[1:100,]) + 
  geom_point(aes(x = 1:100, y = new_AAL)) + 
  geom_hline(yintercept = 134e6) +
  geom_hline(yintercept = 67e6) +
  scale_x_origin() + scale_y_origin()

```

```{r}
buildings <- buildings %>% 
  mutate(bad = case_when(bldg %in% loss.bldg[loss.bldg$new_AAL > 67e6, 'bldg'] ~ TRUE, TRUE ~ FALSE))

load('_data/aoi/aoi.Rdata')
ggplot() + 
  geom_sf(data = sonoma %>% st_union %>% st_crop(aoi), fill = 'grey90', color = 'grey70') +
  geom_sf(data = russian %>% st_transform(6417) %>% st_crop(aoi), size = 1) + 
  geom_sf(data = buildings, aes(color = bad))

temp <- buildings[buildings$bad,]
temp

mapview(temp)

ggplot(buildings %>% arrange(bad)) + 
  geom_point(aes(x = bldg_sqft, y = value, color = bad))


```

