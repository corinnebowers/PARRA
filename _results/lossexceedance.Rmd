---
title: "Untitled"
author: "Corinne"
date: "4/14/2021"
output:
  html_document:
    toc: true 
    toc_float: true
    #toc_depth: 3  
    code_folding: hide
    number_sections: true 
    theme: spacelab   #https://www.datadreaming.org/post/r-markdown-theme-gallery/
    highlight: tango  #https://www.garrickadenbuie.com/blog/pandoc-syntax-highlighting-examples/
---

The purpose of this script is to ...

```{r setup, include = FALSE}
knitr::opts_knit$set(root.dir = 'D:/1-PARRA/')
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
knitr::opts_chunk$set(results = 'hold', fig.show = 'hold', fig.align = 'center')
rm(list=ls())

```

```{r}
## setup information
source('_data/setup.R')
source('_data/plots.R')

## set random seed for reproducibility
set.seed(1)

## load files
load('_data/catalog/catalog.Rdata')
load('_data/aoi/aoi.Rdata')

```


# Compute full loss histogram

## Identify case study storm
```{r}
casestudy <- catalog %>% filter(start_day == ymd('2019-02-25'))
print(casestudy)

```

go to Sherlock and run for this case study
```{r}
load('_results/final/_results/event2019/DV.Rdata')
# load('_results/sept30/event_2019-90/DV.Rdata')

```

## plot real loss vs. simulated loss distribution
```{r}
plot_loss_sim <- function(year, loss.est) {
  g <- loss.sim %>% 
    ggplot() + 
    geom_histogram(aes(x = loss, y = ..density..), color = 'black', fill = 'grey90', 
      bins = sqrt(nrow(loss.sim)), boundary = 0, size = 0.25) + 
    geom_vline(xintercept = loss.est, linetype = 'dashed') + 
    annotate('text', x = loss.est, y = 2e-8, vjust = -0.5, angle = 90,
      label = '2019 Observed', family = 'Segoe UI', size = 8/.pt) +
    scale_x_origin('Loss Estimate ($M)', 
      labels = comma_format(scale = 1e-6, accuracy = 1)) + 
    scale_y_origin('Frequency of Occurrence') + 
    coord_cartesian(xlim = c(0, 225e6))
  return(g)
}

loss.est <- 91.6e6
plot_loss_sim(2019, loss.est)
ggsave('_figures/fig09/fig09_lossdist.png', width = 8.3, height = 5, units = 'cm')

```

```{r}
## percentile
1 - (sum(loss.sim$loss > loss.est) / 1e4)

## maximum event
max(loss.sim$loss)/1e6
max(loss.sim$loss) / loss.est

```

## spatial distribution of loss
```{r}
## census block groups
sonoma_cbgs <- block_groups(state = 'CA', county = 'Sonoma') %>% 
  mutate(group = toNumber(GEOID)) %>% 
  left_join(loss.group %>% mutate(group = toNumber(group)), by = 'group') %>% 
  mutate(loss = ifelse(is.na(loss), 0, loss)) %>% 
  st_transform(6417) %>% st_crop(aoi)
ggplot(sonoma_cbgs) + 
  geom_sf(data = sonoma, fill = 'grey90', color = 'grey60', size = 0.25) +
  geom_sf(aes(fill = loss/1e6), color = NA) + 
  scale_fill_scico('Block Group \nLoss Estimate', palette = 'roma', 
    begin = 0.5, labels = comma_format(prefix = '$', suffix = 'M')) + 
  ggnewscale::new_scale_fill() + 
  geom_sf(aes(fill = loss>0), color = NA, show.legend = FALSE) + 
  scale_fill_manual(values = c('white', NA), na.value = NA) + 
  geom_sf(data = sonoma, fill = NA, size = 0.25, color = 'grey60') +
  geom_sf(data = st_union(sonoma), color = 'grey50', fill = NA) + 
  geom_sf(data = aoi, fill = NA, color = 'grey40') + 
  geom_sf(data = russian %>% st_transform(6417) %>% st_crop(sonoma), size = 0.75) + 
  coord_sf(expand = FALSE) +
  theme(axis.title = element_blank(), axis.text = element_blank(), 
        axis.ticks = element_blank(), axis.line = element_blank(),
        panel.background = element_blank(), plot.background = element_blank(),
        legend.position = c(0.1, 0.275), legend.background = element_blank())
ggsave('_figures/fig09/fig09_lossmap.png', width = 6, height = 9, units = 'cm')

```

## calculate AAL for entire catalog
```{r}
load('_results/final/_results/stochastic/DV.Rdata')
# load('_results/sept30/stochastic-90/DV.Rdata')
loss.stochastic <- loss.sim

AAL <- sum(loss.stochastic$loss)/3200/1e6
AAL
AAL/2

```

## estimate return period for losses 
```{r}
## return period of 2019 event
p <- sum(loss.stochastic$loss > 91.6e6)/3200
percent(p, accuracy = 0.01)
comma(1/p, accuracy = 0.01)

## expected loss due to 1-in-100 year event
loss.stochastic %>% 
  arrange(desc(loss)) %>% 
  mutate(p = (1:nrow(.))/3200) %>% 
  mutate(RP = 1/p) %>% 
  filter(p == 0.01) %>%
  mutate(loss = loss/1e6) %>% pull(loss) %>% 
  comma(prefix = '$', suffix = 'M', accuracy = 0.01)

```

```{r}
## Corringham et al. have 5.2 billion dollars in losses
5.2e3 / 40

```

## mitigation
```{r}
## what happens if we elevate all buildings above the 100-year floodplain?

load('_results/final/_results/elevated/DV.Rdata')
loss.elevated <- loss.sim

sum(loss.elevated$loss)/3200/1e6  #elevated AAL

ggplot() + 
  geom_hline(yintercept = 1e-2, color = 'grey70', linetype = 'dashed') + 
  geom_step(aes(x = sort(loss.stochastic$loss), 
                y = (nrow(loss.stochastic):1)/(nrow(loss.stochastic)+1),
                color = 'Original'), size = 1) + 
  geom_step(aes(x = sort(loss.elevated$loss), 
                y = (nrow(loss.elevated):1)/(nrow(loss.elevated)+1),
                color = 'Elevated'), size = 1) + 
  scale_color_manual(values = c('grey60', 'black')) + 
  scale_x_origin('Loss ($M)', labels = comma_format(scale = 1e-6), 
                 breaks = seq(0, 5e8, 5e7)) + 
  scale_y_log10('Rate of Exceedance') + annotation_logticks(side = 'l')

```


## what happens if we elevate them one at a time?

#### attach different prioritization schemes to buildings dataframe
```{r}
load('_data/buildings/buildings.Rdata')

## add floodplain information
load('_data/NFHL/NFHL.Rdata')
buildings <- buildings %>% 
  mutate(NFHL = unname(unlist(terra::extract(obs, st_coordinates(buildings))))) %>% 
  arrange(desc(NFHL)) %>%
  mutate(id = 1:nrow(.)) %>% 
  group_by(NFHL) %>% 
  mutate(order = sample(id, length(id), replace = FALSE)) %>% 
  ungroup

## add distance to river
buildings <- 
  cbind(st_drop_geometry(buildings), st_coordinates(buildings)) %>% 
  st_as_sf(coords = c('X', 'Y'), crs = 6417)
buildings$dist_m <- buildings %>% 
  st_distance(russian %>% st_transform(6417) %>% st_union) %>% 
  c %>% drop_units

## add elevation
load('_data/lisflood/dem.Rdata')
buildings$elevation <- terra::extract(dem, st_coordinates(buildings))

## add stochastic loss
load('_results/final/_results/stochastic/DV.Rdata')
buildings <- buildings %>% left_join(loss.group, by = c('bldg' = 'group'))

## add 100-year flood elevations
# rp100 <- raster('_data/lisflood/bestfit.max', crs = projection(aoi))
rp100 <- raster('_sensitivity/rp100/sherlock_bestfit/results/bestfit.max', crs = projection(aoi))
buildings$raised_m <- unlist(unname(terra::extract(rast(rp100), st_coordinates(buildings))))

```

```{r}
## load building-level losses for original & elevated case
load('_results/final/_results/stochastic/DV.Rdata')
loss.stochastic <- loss.sim; loss.bldg.stochastic <- loss.group
load('_results/final/_results/elevated/DV.Rdata')
loss.elevated <- loss.sim; loss.bldg.elevated <- loss.group

## check AALs
AAL.bysim <- sum(loss.stochastic$loss)/3200/1e6
AAL.bybldg <- sum(loss.bldg.stochastic$loss)*nrow(loss.stochastic)/3200/1e6
# sum(loss.elevated$loss)/3200/1e6
# sum(loss.bldg.elevated$loss)*nrow(loss.elevated)/3200/1e6

##note: differences are due to the simulation of valuation standard deviations (repeated G(DV) twice)

## choose prioritization scheme
temp <- buildings %>% 
  st_drop_geometry %>% 
  select(bldg, order, dist_m, elevation, loss) %>%
  arrange(dist_m) %>% 
  left_join(loss.bldg.stochastic %>% rename(stochastic = loss), by = c('bldg' = 'group')) %>% 
  left_join(loss.bldg.elevated %>% rename(elevated = loss), by = c('bldg' = 'group')) %>% 
  filter(!is.na(stochastic) | !is.na(elevated))

## find how many buildings need to be elevated
new_AAL <- 
  foreach(i = 0:nrow(temp), .combine = 'c') %do% {
    loss.mitigated <- 
      c(temp$elevated[0:i], temp$stochastic[(i+1):(nrow(temp)+1)])[-(nrow(temp)+1)]
    sum(loss.mitigated)*nrow(loss.stochastic)/3200/1e6
  }
which(new_AAL < AAL.bybldg/2)[1]

load('_results/final/_results/stochastic/INUN.Rdata')
dim(inundation[[1]])

```

```{r}
## compare original AAL
load('_results/final/_results/mitigated/DV_dist_0.Rdata')
sum(loss.sim$loss)/3200/1e6

## compare elevated AAL
load('_results/final/_results/mitigated/DV_dist_1601.Rdata')
sum(loss.sim$loss)/3200/1e6

## look in the range of the recommended mitigation
id <- c(140:160)
mitigated_AAL <- 
  foreach (i = id, .combine = 'c') %do% {
    load(paste0('_results/final/_results/mitigated/DV_dist_', i, '.Rdata'))
    sum(loss.sim$loss)/3200/1e6
  }
plot(id, mitigated_AAL)

mitigated_AAL <- 
  foreach (i = id, .combine = 'c') %do% {
    load(paste0('_results/final/_results/mitigated/DV_dist_', i, '.Rdata'))
    sum(loss.group$loss)*nrow(loss.sim)/3200/1e6
  }
ggplot() + 
  geom_point(aes(x = id, y = mitigated_AAL))

```

## get mitigated loss exceedance curve
```{r}
load('_results/final/_results/mitigated/DV_dist_150.Rdata')
loss.mitigated <- loss.sim

## plot original vs. mitigated loss exceedance curve
ggplot() + 
  geom_hline(yintercept = 1e-2, color = 'grey70', linetype = 'dashed') + 
  annotate('text', x = 225e6, y = 1e-2, hjust = 0, vjust = -0.5,
           label = '"100 Year Event"', fontface = 'italic', 
           family = 'Segoe UI', size = 7/.pt, color = 'grey70') + 
  geom_step(aes(x = sort(loss.stochastic$loss), 
                y = (nrow(loss.stochastic):1)/3200, color = 'Original'), size = 0.75) +
  geom_step(aes(x = sort(loss.mitigated$loss), 
                y = (nrow(loss.mitigated):1)/3200, color = 'Mitigated'), size = 0.75) +
  scale_x_origin('Loss Estimate ($M)', breaks = seq(0, 5e8, 5e7),
                 labels = comma_format(scale = 1e-6)) + 
  scale_y_log10('Rate of Exceedance, \u03bb', labels = scientific) +
  scale_color_manual('Building \nElevations', values = c('black', 'grey60'),
                     breaks = c('Original', 'Mitigated')) + 
  annotation_logticks(sides = 'l') + 
  theme(legend.position = c(0.75, 0.75))
ggsave('_figures/fig10_mitigated.png', width = 8.3, height = 6, units = 'cm')

```

```{r}
## what is the average horizontal difference?
cbind(
  stochastic = sort(loss.stochastic$loss),
  mitigated = sort(loss.mitigated$loss),
  p = (nrow(loss.stochastic):1)/(nrow(loss.stochastic)+1)) %>% 
  as.data.frame %>% 
  mutate(diff = stochastic-mitigated) %>% 
  ggplot() + 
  geom_hline(yintercept = 10^c(-4:0), color = 'grey90') + 
  geom_point(aes(x = diff/1e6, y = p)) + 
  scale_y_log10() + scale_x_origin()
  
```


```{r}
## calculate the mitigated AAL
sum(loss.stochastic$loss)/1e6/3200
sum(loss.mitigated$loss)/1e6/3200

## return period of 2019 event
p <- sum(loss.mitigated$loss > 91.6e6)/3200
percent(p, accuracy = 0.01)
comma(1/p, accuracy = 0.01)

## expected loss due to 1-in-100 year event
loss.mitigated %>% 
  arrange(desc(loss)) %>% 
  mutate(p = (1:nrow(.))/3200) %>% 
  mutate(RP = 1/p) %>% 
  filter(p == 0.01) %>%
  mutate(loss = loss/1e6) %>% pull(loss) %>% 
  comma(prefix = '$', suffix = 'M', accuracy = 0.01)

```



```{r}
## grab simulation tracker
simulations <- attr(damage, 'sim')

# ## elevate buildings iteratively & calculate new AAL
# start <- Sys.time()
# num_cores <- 5
# cl <- parallel::makeCluster(num_cores)
# registerDoSNOW(cl)
# pb <- txtProgressBar(min = 0, max = nrow(loss.bldg), style = 3)
# loss.bldg$new_AAL <-
#   foreach(
#     i = 1:nrow(loss.bldg), 
#     .combine = 'c', .packages = 'tidyverse', 
#     .options.snow = list(progress = function(n) setTxtProgressBar(pb, n))) %dopar% {
#       simulations$loss <- 
#         rbind(
#           loss.stochastic[[1]] %>% filter(!(bldg %in% loss.bldg$bldg[1:i])),
#           loss.mitigated[[1]] %>% filter(bldg %in% loss.bldg$bldg[1:i])) %>% 
#         select(-bldg, -n.damage, -n.inun) %>% 
#         apply(2, sum)
#       sum(simulations$loss)/3200
#     }
# stopCluster(cl)
# Sys.time() - start

load('loss.bldg.Rdata')

ggplot(loss.bldg[1:100,]) + 
  geom_point(aes(x = 1:100, y = new_AAL)) + 
  geom_hline(yintercept = 134e6) +
  geom_hline(yintercept = 67e6) +
  scale_x_origin() + scale_y_origin()

```

```{r}
buildings <- buildings %>% 
  mutate(bad = case_when(bldg %in% loss.bldg[loss.bldg$new_AAL > 67e6, 'bldg'] ~ TRUE, TRUE ~ FALSE))

load('_data/aoi/aoi.Rdata')
ggplot() + 
  geom_sf(data = sonoma %>% st_union %>% st_crop(aoi), fill = 'grey90', color = 'grey70') +
  geom_sf(data = russian %>% st_transform(6417) %>% st_crop(aoi), size = 1) + 
  geom_sf(data = buildings, aes(color = bad))

temp <- buildings[buildings$bad,]
temp

mapview(temp)

ggplot(buildings %>% arrange(bad)) + 
  geom_point(aes(x = bldg_sqft, y = value, color = bad))


```

