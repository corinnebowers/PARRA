---
title: "Sonoma County AR Case Study"
author: "Corinne Bowers"
date: "3/9/2022"
output:
  html_document:
    toc: true 
    toc_float: true
    #toc_depth: 3  
    code_folding: hide
    number_sections: true 
    theme: spacelab   #https://www.datadreaming.org/post/r-markdown-theme-gallery/
    highlight: tango  #https://www.garrickadenbuie.com/blog/pandoc-syntax-highlighting-examples/
---

The purpose of this script is to reproduce figures and numeric results for the paper "A Performance-Based Approach to Quantify Atmospheric River Flood Risk" (https://doi.org/10.5194/nhess-2021-337). 
We implement a model-by-model comparison of the PARRA simulations at each pinch point vs. the observed values from a selection of notable atmospheric river (AR) events in Sonoma County, California. 

Please note: all figures are formatted for publication, therefore certain features may not display correctly in this markdown file. 

```{r setup, include = FALSE}
knitr::opts_knit$set(root.dir = 'D:/1-PARRA/')
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
knitr::opts_chunk$set(results = 'hold', fig.show = 'hold', fig.align = 'center')
rm(list=ls())

```

```{r}
## set random seed for reproducibility
set.seed(2021)

## setup information
source('_data/setup.R')
source('_data/plots.R')

## load required packages
require(dataRetrieval)

## set parallel backend
num_cores <- 5

## load historic catalog
load('_data/catalog/catalog.Rdata')

## load location information
load('_data/lisflood/dem.Rdata')
load('_data/aoi/aoi.Rdata')
load('_data/NHD/NHD.Rdata')

## load building information
load('_data/buildings/buildings.Rdata')
load('_data/foundations/foundations.Rdata')

## load depth-damage relationships
load('_data/depthdamage/depthdamage.Rdata')

```

```{r echo = FALSE}
## should figures be saved out for the publication?
publish <- FALSE

if (!publish) {
  theme_set(
    theme_classic() + theme(
      text = element_text(family = 'Segoe UI', size = 12),
      axis.line = element_line(size = 0.5),
      axis.ticks = element_line(size = 0.5, color = 'black'),
      legend.key.size = unit(0.5, 'cm')))
  }

```

# Define area of interest

Figure 2 in the paper shows the study area.
The first panel is a map of Sonoma County, with important cities/towns and rivers/creeks identified and with the study area marked by a shaded rectangle.
The second plot is a map of California with the Russian River and Sonoma County highlighted for geographic context.
Additional text and callout lines were added outside of R through the image editing software Inkscape.

### Plot Sonoma County

```{r}
## load California county polygons
california <- counties(state = 'CA', class= 'sf') %>% st_transform(6417)

## define highlighted cities within Sonoma County
cities <- matrix(
  c(38.507930, -122.985860, 'Guerneville', 1, 
    38.616588, -122.858989, 'Healdsburg', 2, 
    38.46539312043779, -123.00905110596939, 'Monte Rio', 1, 
    38.708491304036954, -122.9028864411151, 'Geyserville', 1,
    38.47356804731463, -122.89069701384281, 'Forestville', 1), 
  byrow = TRUE, ncol = 4) %>%
  data.frame %>%
  setNames(c('lat', 'long', 'city', 'importance')) %>%
  mutate(lat = toNumber(lat), long = toNumber(long)) %>%
  st_as_sf(coords = c('long', 'lat'), crs = 4269) %>% 
  st_transform(6417)

## plot figure 2a: Sonoma County study area
```

```{r fig2a, echo = FALSE}
ggplot() + 
  geom_sf(data = st_union(sonoma), fill = 'grey90', color = NA, alpha = 0.5) +
  geom_sf(data = aoi, fill = 'grey70', color = 'grey40', alpha = 0.35) +
  geom_sf(data = st_union(sonoma), fill = NA, color = 'grey25', size = 0.75) +
  geom_sf(data = russian %>% summarize(GNIS_Name = GNIS_Name[1]) %>%
            st_transform(6417) %>% st_crop(st_union(sonoma)),
          color = scico(5, palette = 'roma')[5], size = 1) +
  geom_sf(data = creeks %>% st_intersection(st_union(sonoma)),
          color = scico(5, palette = 'roma')[5]) +
  geom_sf(data = cities, aes(size = importance), show.legend = FALSE) + 
  scale_size_manual(values = c(1.5, 1.5)) + 
  annotation_scale(width_hint = 0.25, height = unit(0.25, 'cm'),
                   pad_x = unit(0.5, 'cm'), pad_y = unit(0.5, 'cm'),
                   text_family = 'Segoe UI', text_cex = 2/3) + 
  theme_void() 
if (publish) ggsave('_figures/fig02/fig02_sonoma.png', width = 8.5, units = 'cm', dpi = 600)

```

### Plot California

```{r}
## plot figure 2b: California
```

```{r fig2b, echo = FALSE}
california <-
  california %>% st_union %>% st_sf %>% st_cast('POLYGON') %>% .[1,] %>% 
    st_intersection(california %>% st_cast('POLYGON'), .)

ggplot() + 
  geom_sf(data = california, fill = 'grey90', color = 'grey40', alpha = 0.5, size = 0.25) + 
  geom_sf(data = california %>% filter(NAME == 'Sonoma'),
          fill = 'grey50', color = 'grey25', size = 0.5) +
  geom_sf(data = st_union(california), fill = NA, color = 'grey25', size = 0.5) + 
  theme_void() 
ggsave('_figures/fig02/fig02_california.png', width = 3, units = 'cm', dpi = 600)

```

# $f(AR)$

The first component model in the PARRA framework is $f(AR)$, or the representation of AR intensity.  

## Generate historic catalog

We first start by generating a historic catalog of ARs that have occurred in the Sonoma County study area over a 32-year period from 1997 to 2019. 
All data sources and calculations can be found in the script `catalog.Rmd`.
Results are summarized below and included in the paper as Table 1.

```{r tab1, echo = FALSE}
catalog %>% 
  mutate(cat = case_when(cat==0~1, TRUE~cat)) %>% 
  group_by(cat) %>% 
  summarize(
    n = length(AR),
    ivt = mean(IVT_max), 
    dur = mean(duration), 
    prcp = mean(precip_mm), 
    qp = mean(Qp_m3s), 
    tp = Mean(tp_hrs)) %>% 
  gt %>% 
  fmt_number(c(cat, n), decimals = 0) %>% 
  fmt_number(c(ivt, dur, prcp, qp, tp), decimals = 1) %>% 
  cols_label(
    cat = 'Category', 
    n = 'Events', 
    ivt = 'IVT (kg/m/s)',
    dur = 'Duration (hrs)',
    prcp = 'Precipitation (mm)', 
    qp = 'Peak Streamflow (m^3/s)', 
    tp = 'Time to Peak Streamflow (hrs)') %>% 
  tab_header(title = 'Sonoma County Historic Catalog', 
             subtitle = 'Mean Values by AR Intensity Category') %>% 
  tab_options(heading.background.color = '#d9d9d9', 
              column_labels.background.color = '#f2f2f2')

```

## Plot AR characteristics from the historic catalog

We summarize ARs in terms of two variables: maximum recorded integrated water vapor transport (IVT, kg/m/s) and duration (hrs).
Figure 3 from the paper summarizes the maximum IVT and duration values from the Sonoma County historic catalog.
The bottom and left histograms represent the marginal distributions of maximum IVT and duration, respectively. 
The scatterplot shows the joint distribution of these two variables for all ARs in the historic catalog, and the background colors show the AR intensity categories from Ralph et al. (2020). 

```{r}
## create dataframe to represent AR intensity categories as background colors
IVT_breaks <- seq(250, 1250, 250) + 125
duration_breaks <- seq(0, 168, 24) + 12
df <- expand.grid(IVT = IVT_breaks, duration = duration_breaks)
ARcat <- function(IVT, duration) {
  if (duration >= 48) {
    case_when(
      IVT>=1000 ~ 5, IVT>=750 ~ 4, IVT>=500 ~ 3, TRUE ~ 2)
  } else if (duration >= 24) {
    case_when(
      IVT>=1250 ~ 5, IVT>=1000 ~ 4, IVT>=750 ~ 3, IVT>=500 ~ 2, TRUE ~ 1)
  } else {
    case_when(
      IVT>=1250 ~ 4, IVT>=1000 ~ 3, IVT>=750 ~ 2, IVT>=500 ~ 1, TRUE ~ 0)
  }
}
for (i in 1:nrow(df)) {df$cat[i] <- ARcat(df$IVT[i], df$duration[i])}
df <- df %>% mutate(cat = ifelse(cat == 0, 1, cat))

## plot figure 3: maximum IVT vs. duration for the historic catalog
```

```{r fig3, echo = FALSE}
## scatterplot of IVT vs. duration
g <- ggplot(df) + 
  geom_raster(aes(x = IVT, y = duration, fill = factor(cat)), alpha = 0.6) +
  geom_point(data = catalog, aes(x = IVT_max, y = duration), color = 'grey10', size = 0.5) + 
  scale_fill_manual('Intensity \nCategory', values = roma.colors[5:1]) + 
  scale_x_continuous(
    limits = c(250, NA), expand = c(0,0), 
    breaks = seq(250, 1500, 250), minor_breaks = seq(250, 1500, 250)) + 
  scale_y_continuous(
    'Storm Duration (hrs)', expand = c(0,0), 
    breaks = seq(0, 240, 24), minor_breaks = seq(0, 240, 24)) + 
  coord_cartesian(ylim = c(0,192)) + 
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(),
        axis.title.y = element_blank(), axis.text.y = element_blank(),
        plot.margin = margin(2,20,2,2))

## histogram of maximum IVT
g.ivt <- ggplot(catalog) + 
  geom_histogram(aes(x = IVT_max), color = 'black', fill = 'grey90', 
                 bins = sqrt(nrow(catalog)), boundary = 250, size = 0.25) + 
  scale_x_continuous(
    expression(paste('Maximum IVT (kgâ‹…', m^{-1}, s^{-1}, ')')),
    breaks = seq(0, 1e5, 250), expand = c(0,0), limits = c(250,1500)) + 
  scale_y_origin() + 
  coord_cartesian(xlim = c(250, NA), clip = 'off') + 
  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), 
        axis.ticks.y = element_blank(), axis.line.y = element_line(color = NA),
        plot.margin = margin(2,2,2,2))

## histogram of storm duration
g.dur <- ggplot(catalog) + 
  geom_histogram(aes(x = duration), color = 'black', fill = 'grey90',
                 bins = sqrt(nrow(catalog)), boundary = 0, size = 0.25) + 
  scale_x_continuous('Storm Duration (h)', expand = c(0,0), 
                     breaks = seq(0, 240, 24), minor_breaks = seq(0, 240, 24)) + 
  scale_y_origin() +
  coord_flip(xlim = c(0,192), clip = 'off') +
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(), 
        axis.ticks.x = element_blank(), axis.line.x = element_line(color = NA),
        plot.margin = margin(2,2,2,2))

## combine plot panels into one figure
plot_grid(g, g.ivt, nrow = 2, align = 'v', axis = 'lr', rel_heights = c(3,1)) %>% 
  plot_grid(
    plot_grid(g.dur, NULL, nrow = 2, rel_heights = c(3,1)), ., 
    align = 'h', rel_widths = c(1,4)) 
if (publish) ggsave('_figures/fig03_AR.png', height = 6, width = 8.3, units = 'cm', dpi = 600)

```


# $f(PRCP|AR)$

The second component model is $f(PRCP|AR)$, which estimates precipitation as a function of two AR characteristics, maximum IVT ($IVT$) and duration ($DUR$). 

## Fit precipitation regression model

The precipitation component model uses a weighted least squares (WLS) linear regression to estimate a total precipitation (mm) averaged over the inlet watershed. The form of the equation is as follows: 

$$ PRCP_i = \beta_0 + \beta_1 (IVT_i) + \beta_2 (DUR_i) + \beta_3 (IVT_i* DUR_i) + \sigma_i $$

The WLS regression was chosen to account for the significant heterskedasticity in the data. 
The uncertainty $\sigma_i$ is represented by a mixture model, with 90\% of errors based on the bulk distribution and 10\% of errors based on the 10\% most extreme AR events in the historic catalog.
Model coefficients are displayed below.

```{r}
## load precipitation component model functions
source('_scripts/2_PRCP/PRCP.R')

## fit precipitation regression
fit_precip(catalog)

## display fitted regression values
```

```{r echo = FALSE}
model.prcp$coefficients %>% 
  t %>% as.data.frame %>% 
  gt %>% 
  fmt_number(columns = c(`(Intercept)`, IVT_max, duration, `IVT_max:duration`), n_sigfig = 3) %>% 
  cols_label(
    `(Intercept)` = 'Intercept',
    IVT_max = 'Max IVT', 
    duration = 'Duration', 
    `IVT_max:duration` = 'Max IVT * Duration') %>% 
  tab_header(title = 'Precipitation Regression Coefficients') %>% 
  tab_options(heading.background.color = '#d9d9d9', 
              column_labels.background.color = '#f2f2f2')

```

Figures 4(a)-(b) show the regression fit vs. the observed data.
In 4(a) the relationship between maximum IVT and precipitation is shown at three specified duration values (*DUR* = 6, 24, & 72 hours). 
In 4(b) the relationship between duration and precipitation is shown at three specified maximum IVT values (*IVT* = 250, 500, & 1000 kg/m/s).
Colors in each panel represent the values of the unplotted dimension in each, i.e., duration in the first panel (maximum IVT vs. precipitation) and maximum IVT in the second panel (duration vs. precipitation)

```{r}
## plot figures
## 4(a): scatterplot of maximum IVT vs. precipitation and 
## 4(b): scatterplot of duration vs. precipitation
```

```{r fig4ab, echo = FALSE}
g1 <- ggplot(catalog) + 
  geom_point(data = catalog %>% filter(duration <= 6), 
    aes(x = IVT_max, y = precip_mm), color = roma.colors[3], size = 0.5) + 
  geom_point(data = catalog %>% filter(duration >= 72), 
    aes(x = IVT_max, y = precip_mm), color = roma.colors[5], size = 0.5) + 
  geom_point(data = catalog %>% filter(duration >= 6 & duration <= 72),
    aes(x = IVT_max, y = precip_mm, color = duration), 
    size = 0.5, show.legend = FALSE) + 
  scale_color_scico(palette = 'roma', begin = 0.5) +
  ggnewscale::new_scale_color() + 
  geom_line(aes(x = IVT_max,
    y = catalog %>% select(IVT_max) %>% 
      mutate(duration = 6) %>% predict(model.prcp, .),
    color = '6'), size = 0.75) + 
  geom_line(aes(x = IVT_max,
    y = catalog %>% select(IVT_max) %>% 
      mutate(duration = 24) %>% predict(model.prcp, .),
    color = '24'), size = 0.75) + 
  geom_line(aes(x = IVT_max,
    y = catalog %>% select(IVT_max) %>% 
      mutate(duration = 72) %>% predict(model.prcp, .),
    color = '72'), size = 0.75) + 
  scale_x_continuous(
    expression(paste('Maximum IVT (kgâ‹…', m^{-1}, s^{-1}, ')')),
    limits = c(250, NA), expand = c(0,0), 
    breaks = seq(250, 1500, 250), minor_breaks = seq(250, 1500, 250)) + 
  scale_y_origin('Storm Total Precipitation (mm)') + 
  scale_color_manual('Duration (h)', 
    values = roma.colors[5:3], 
    breaks = c('72', '24', '6')) + 
  coord_cartesian(clip = 'off') + 
  # guides(color = guide_legend(title.vjust = 1.5)) +
  theme(legend.position = 'bottom', 
        legend.background = element_rect(fill = NA, color = NA),
        legend.text = element_text(margin = margin(0, 0, 0, -4)))

g2 <- ggplot(catalog) + 
  geom_point(data = catalog %>% filter(IVT_max <= 250), 
    aes(x = duration, y = precip_mm), color = roma.colors[3], size = 0.5) + 
  geom_point(data = catalog %>% filter(IVT_max >= 1000), 
    aes(x = duration, y = precip_mm), color = roma.colors[1], size = 0.5) + 
  geom_point(data = catalog %>% filter(IVT_max >= 250 & IVT_max <= 1000),
    aes(x = duration, y = precip_mm, color = IVT_max), 
    size = 0.5, show.legend = FALSE) + 
  scale_color_scico(palette = 'roma', end = 0.5, direction = -1) +
  ggnewscale::new_scale_color() + 
  geom_line(aes(x = duration,
    y = catalog %>% select(duration) %>% 
      mutate(IVT_max = 250) %>% predict(model.prcp, .),
    color = '250'), size = 0.75) + 
  geom_line(aes(x = duration,
    y = catalog %>% select(duration) %>% 
      mutate(IVT_max = 500) %>% predict(model.prcp, .),
    color = '500'), size = 0.75) + 
  geom_line(aes(x = duration,
    y = catalog %>% select(duration) %>% 
      mutate(IVT_max = 1000) %>% predict(model.prcp, .),
    color = '1000'), size = 0.75) + 
  scale_x_continuous(
    'Storm Duration (hrs)', expand = c(0,0), 
    breaks = seq(0, 240, 24), minor_breaks = seq(0, 240, 24)) + 
  # scale_y_origin('Storm Total Precipitation (mm)') + 
  scale_y_origin() + 
  scale_color_manual(expression(paste('Maximum IVT (kgâ‹…', m^{-1}, s^{-1}, ')')), 
    values = roma.colors[1:3], 
    breaks = c('1000', '500', '250')) + 
  coord_cartesian(xlim = c(0,NA), clip = 'off') + 
  guides(color = guide_legend(title.vjust = 1.5)) +
  theme(legend.position = 'bottom', 
        legend.background = element_rect(fill = NA, color = NA),
        legend.text = element_text(margin = margin(0, 0, 0, -4)))

if (!publish) g1
if (!publish) g2

```


## Assess distribution fit

Because we are using the component model for generating new synthetic precipitation realizations, we assessed model fit based on the accuracy in reproducing the entire distribution of precipitation rather than in replicating individual records. 
We present two assessment tools here. 

The first assessment is a visual check for linearity in the quantile plot, which plots the sorted values of one distribution against the sorted values of another. 
This is shown as Figure 4(c) in the paper.

```{r}
## generate one stochastic realization of PRCP for every event in the historic catalog
precip.qq <- 
  generate_precip(
    AR = catalog %>% transmute(n.AR = 1:nrow(.), IVT_max, duration, sm), 
    model.prcp, se.prcp,
    probabilistic = TRUE, n.precip = 1) %>% 
  rename(precip_sim = precip_mm) %>% 
  left_join(catalog %>% transmute(n.AR = 1:nrow(.), precip_obs = precip_mm),
            by = 'n.AR')
precip.max <- max(c(max(precip.qq$precip_sim), max(precip.qq$precip_obs)))

## plot figure 4(c): quantile plot of observed vs. simulated precipitation for the historic catalog
```

```{r fig4c, echo = FALSE}
g3 <- ggplot(precip.qq) + 
  geom_point(aes(x = sort(precip_obs), y = sort(precip_sim)), size = 0.75) + 
  coord_cartesian(xlim = c(NA, precip.max), ylim = c(NA, precip.max)) + 
  scale_x_continuous(
    'Observed Precipitation Quantile (mm)',
    limits = c(0, precip.max), expand = expansion(mult = c(0, 0.25))) + 
  scale_y_continuous(
    'Simulated Precipitation Quantile (mm)',
    limits = c(0, precip.max), expand = expansion(mult = c(0, 0.25))) + 
  geom_parity()
if (!publish) g3 

```

```{r fig4, include = publish, echo = FALSE}
## generate figure 4
plot_grid(
  g1 + 
    theme(
      legend.position = 'none',
      axis.title.y = element_text(color = NA), 
      plot.margin = margin(c(1,25,1,25)),
      plot.background = element_rect(fill = NA, color = NA)), 
  plot_grid(NULL, get_legend(g1), rel_widths = c(1,100)), 
  g2 + 
    labs(y = rep(' ', 60) %>% paste(collapse = '') %>% paste('Storm Total Precipitation (mm)')) +
    theme(legend.position = 'none', plot.margin = margin(c(1,25,1,25))), 
  plot_grid(NULL, get_legend(g2), rel_widths = c(1,100)), 
  g3 + 
    theme_bw_custom() + 
    theme(plot.margin = margin(c(0,25,5,25))),
  nrow = 5, align = 'v', rel_heights = c(10,1.5,10,2,18),
  labels = c('(a)', '', '(b)', '', '(c)'), label_fontfamily = 'Segoe UI', label_size = 12, 
  label_x = 0.225, label_y = 0.95
)
ggsave('_figures/fig04_prcpfit.png', width = 8.3, height = 15, units = 'cm', dpi = 600)

```

The second is the two-sample Kolmogorov-Smirnov (K-S) test, which is a formal test of fit. 
If the simulated CDF is pulled from the same distribution as the observed CDF, then the distance $d$ between the two follows the K-S distribution, and the following is true: 

$$ \mathrm{P} \left(d > 1.731\sqrt{\frac{2}{N}} \right) \approx 0.05 
\to d_{crit} = 1.731\sqrt{\frac{2}{N}} $$
where $N$ = the number of events in the historic catalog.

We define the distance between the observed and simulated precipitation CDFs as $d_{PRCP}$ and perform a hypothesis test to determine whether $\frac{d_{PRCP}}{d_{crit}} \leq 1$ at a significance level of 1%. 
We repeat this process 100 times to account for the probabilistic nature of the simulation process and report the mean test statistic below.

```{r}
## determine d.crit, the value of the 95% confidence threshold
d.crit <- 1.628 * sqrt(2/nrow(catalog))

## calculate the K-S statistic for 100 simulations
n <- 100
cl <- parallel::makeCluster(num_cores)
registerDoSNOW(cl)
ks.value <- 
  foreach (i = 1:n, 
    .combine = 'c', .packages = c('tidyverse', 'pracma'), 
    .export = 'generate_precip') %dopar% {
      ## generate one realization of precipitation
      precip.ks <- generate_precip(
        AR = catalog %>% transmute(n.AR = 1:nrow(.), IVT_max, duration, sm), 
        model.prcp, se.prcp,
        probabilistic = TRUE, n.precip = 1)
      ## create a dataframe of sorted values 
      sorted <- data.frame(
        precip.obs = sort(catalog$precip_mm),
        precip.sim = sort(precip.ks$precip_mm)) %>% 
        mutate(p = (1:nrow(.))/(nrow(.)+1))
      ## find the maximum distance between the observed CDF and simulated CDF
      data.frame(
        precip = seq(0, min(c(max(sorted$precip.obs), max(sorted$precip.sim))), 
                     length.out = 1000)) %>% 
        mutate(p.obs = interp1(x = sorted$precip.obs, y = sorted$p, xi = precip)) %>% 
        mutate(p.sim = interp1(x = sorted$precip.sim, y = sorted$p, xi = precip)) %>% 
        mutate(d = abs(p.obs-p.sim)) %>% 
        mutate(ks = d/d.crit) %>% 
        arrange(desc(ks)) %>% 
        pull(ks) %>% max
  }
stopCluster(cl)

## report K-S statistic
```

```{r echo = FALSE}
mean(ks.value) %>% as.data.frame %>% 
  setNames('Mean K-S Statistic') %>% 
  gt %>% 
  fmt_number(`Mean K-S Statistic`, decimals = 3) %>% 
  tab_options(column_labels.background.color = '#f2f2f2')

```

```{r include = FALSE}
# ## plot distribution of K-S statistic 
# ggplot() + 
#   geom_histogram(aes(x = ks.value, y = ..density..), 
#     color = 'black', fill = 'grey90', bins = sqrt(length(ks.value))) + 
#   geom_vline(xintercept = 1, linetype = 'dashed', size = 1) + 
#   scale_x_continuous('Kolmogorov-Smirnov Statistic') + 
#   scale_y_origin('Probability of Occurrence')

```

Based on a visual assessment of the quantile plot and the fact that the test statistic is much smaller than 1, we consider the fit of the precipitation component model as sufficient to accurately represent the historic catalog.

## Identify case study AR events

We have chosen four events as case studies to show how the comparison between observed and simulated values can generate new insights about the precipitation totals associated with different AR events. 
The four events are the two most recent Category 3 (strong) and the two most recent Category 5 (exceptional) events.
Of these four events, one of each category was a "notable"  event (caused significant and newsworthy losses that were totaled at the community level, and led to state and/or federal disaster declarations) and one of each category was not notable. 
The table below shows the AR and precipitation values associated with each of these four events.

```{r}
## identify case study AR events
casestudy <- catalog %>% 
  arrange(desc(start_day)) %>% 
  group_by(cat) %>% 
  slice(1:2) %>% 
  ungroup %>% 
  filter(cat == 3 | cat == 5) %>% 
  arrange(start_day)

## show the event characteristics as a formatted table
```

```{r echo = FALSE}
casestudy %>%
  select(start_day, end_day, cat, IVT_max, duration, precip_mm, Qp_m3s, tp_hrs, sm) %>%
  gt %>%
  fmt_date(columns = c(start_day, end_day), date_style = 'iso') %>%
  fmt_number(columns = c(cat, IVT_max, duration), decimals = 0) %>%
  fmt_number(columns = c(precip_mm, Qp_m3s, tp_hrs, sm), decimals = 1) %>%
  cols_label(
    start_day = 'Start Day', end_day = 'End Day', cat = 'AR Category',
    IVT_max = 'Maximum IVT (kg/m/s)',
    duration = 'Storm Duration (hrs)',
    precip_mm = 'Total Precipitation (mm)',
    Qp_m3s = 'Peak Streamflow (m^3/s)',
    tp_hrs = 'Time to Peak Streamflow (hrs)',
    sm = 'Antecedent Soil Moisture (mm/m)') %>%
  tab_header(title = 'Case Study AR Events') %>%
  tab_options(heading.background.color = '#d9d9d9',
              column_labels.background.color = '#f2f2f2')

```


## Compare observed vs. simulated values

We generate 1,000 realizations of precipitation given the observed maximum IVT and duration from each event, then compare those distributions to the true observed precipitation. 
The results are included as Figure 5 in the paper. 

```{r}
## generate 1,000 probabilistic realizations of PRCP for each of the cast study events

## cat 3 impactful
cat3a <- catalog %>% filter(cat == 3) %>% arrange(desc(start_day)) %>% .[2,]
precip3a <- 
  generate_precip(
    AR = cat3a %>% transmute(n.AR = 1:nrow(.), IVT_max, duration, sm), 
    model.prcp, se.prcp,
    probabilistic = TRUE,
    n.precip = 1e3)

## cat 3 non-impactful
cat3b <- catalog %>% filter(cat == 3) %>% arrange(desc(start_day)) %>% .[1,]
precip3b <- 
  generate_precip(
    AR = cat3b %>% transmute(n.AR = 1:nrow(.), IVT_max, duration, sm), 
    model.prcp, se.prcp,
    probabilistic = TRUE,
    n.precip = 1e3)

## cat 5 impactful
cat5b <- catalog %>% filter(cat == 5) %>% arrange(desc(start_day)) %>% .[1,]
precip5b <- 
  generate_precip(
    AR = cat5b %>% transmute(n.AR = 1:nrow(.), IVT_max, duration, sm), 
    model.prcp, se.prcp,
    probabilistic = TRUE,
    n.precip = 1e3)

## cat 5 non-impactful
cat5a <- catalog %>% filter(cat == 5) %>% arrange(desc(start_day)) %>% .[2,]
precip5a <- 
  generate_precip(
    AR = cat5a %>% transmute(n.AR = 1:nrow(.), IVT_max, duration, sm), 
    model.prcp, se.prcp,
    probabilistic = TRUE,
    n.precip = 1e3)

## plot figure 5: histogram of observed vs. simulated precipitation for case study events
```

```{r fig5, include = publish, echo = FALSE}
## set shared parameters for all panels
ymax <- 0.135
g.base <- ggplot() + 
  scale_color_manual(name = '', values = 'grey25') +
  scale_x_continuous(limits = c(0,500), expand = expansion(mult = c(0,0.01))) + 
  scale_y_origin(breaks = seq(0, 0.5, 0.025)) + 
  labs(x = 'Storm Total Precipitation (mm)', y = 'Probability of Occurrence') +
  theme(
    legend.background = element_blank(),
    legend.key.size = unit(2, 'mm'), 
    legend.spacing.x = unit(0.5, 'mm'),
    plot.background = element_rect(fill = NA, color = NA)) +
  coord_cartesian(ylim = c(0, ymax)) 

## plot cat 3 impactful
gTL <- g.base + 
  ggtitle(label = waiver(), subtitle = 'February 2019') + 
  geom_histogram(
    data = precip3b, aes(x = precip_mm, y = ..count../1e3), 
    color = 'black', fill = 'grey90', binwidth = 10, boundary = 0, size = 0.25) + 
  geom_segment(data = catalog %>% filter(cat == 3),
    aes(x = precip_mm, xend = precip_mm, y = ymax-0.0025, yend = 1,
        color = 'All Cat 3 Events'),
    lineend = 'square', size = 0.25) +
  geom_vline(xintercept = cat3b$precip_mm, linetype = 'dashed') + 
  annotate(geom = 'text', angle = 90,
    x = cat3b$precip_mm, y = 0.075, hjust = 0, vjust = 1.5,
    label = 'Observed', family = 'Segoe UI', size = 8/.pt) +
  theme(axis.title.x = element_blank()) + 
  theme(legend.position = c(0.55, 1.035), plot.margin = margin(5,5,5,5))

## plot cat 3 non-impactful
gBL <- g.base + 
  ggtitle(label = waiver(), subtitle = 'January 2019') + 
  geom_histogram(
    data = precip3a, aes(x = precip_mm, y = ..count../1e3), 
    color = 'black', fill = 'grey90', binwidth = 10, boundary = 0, size = 0.25) + 
  geom_segment(data = catalog %>% filter(cat == 3),
    aes(x = precip_mm, xend = precip_mm, y = ymax-0.0025, yend = 1,
        color = 'All Cat 3 Events'),
    lineend = 'square', size = 0.25) +
  geom_vline(xintercept = cat3a$precip_mm, linetype = 'dashed') + 
  annotate(geom = 'text', angle = 90,
    x = cat3a$precip_mm, y = 0.0875, hjust = 0, vjust = 1.5,
    label = 'Observed', family = 'Segoe UI', size = 8/.pt) +
  theme(legend.position = c(0.55, 1.035), plot.margin = margin(5,5,5,5))

## plot cat 5 impactful
cat5b <- catalog %>% filter(cat == 5) %>% arrange(desc(start_day)) %>% .[1,]
gTR <- g.base + 
  ggtitle(label = waiver(), subtitle = 'January 2017') + 
  geom_histogram(
    data = precip5b, aes(x = precip_mm, y = ..count../1e3), 
    color = 'black', fill = 'grey90', binwidth = 10, boundary = 0, size = 0.25) + 
  geom_segment(data = catalog %>% filter(cat == 5),
    aes(x = precip_mm, xend = precip_mm, y = ymax-0.0025, yend = 1,
        color = 'All Cat 5 Events'),
    lineend = 'square', size = 0.25) +
  geom_vline(xintercept = cat5b$precip_mm, linetype = 'dashed') + 
  annotate(geom = 'text', angle = 90,
    x = cat5b$precip_mm, y = 0.075, hjust = 0, vjust = 1.5,
    label = 'Observed', family = 'Segoe UI', size = 8/.pt) +
  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) + 
  theme(legend.position = c(0.675, 1.035), plot.margin = margin(5,10,5,5))

## plot cat 5 non-impactful
gBR <- g.base + 
  ggtitle(label = waiver(), subtitle = 'October 2016') + 
  geom_histogram(
    data = precip5a, aes(x = precip_mm, y = ..count../1e3), 
    color = 'black', fill = 'grey90', binwidth = 10, boundary = 0, size = 0.25) + 
  geom_segment(data = catalog %>% filter(cat == 5),
    aes(x = precip_mm, xend = precip_mm, y = ymax-0.0025, yend = 1,
        color = 'All Cat 5 Events'),
    lineend = 'square', size = 0.25) +
  geom_vline(xintercept = cat5a$precip_mm, linetype = 'dashed') + 
  annotate(geom = 'text', angle = 90,
    x = cat5a$precip_mm, y = 0.075, hjust = 0, vjust = 1.5,
    label = 'Observed', family = 'Segoe UI', size = 8/.pt) +
  theme(axis.title.y = element_blank()) + 
  theme(legend.position = c(0.675, 1.035), plot.margin = margin(5,10,5,5))

## plot left/right and top/bottom labels
g.sides <- ggplot() + 
  theme(
    axis.line = element_line(color = NA), 
    plot.background = element_rect(fill = NA, color = NA),
    axis.title = element_blank(), 
    axis.text = element_blank(), 
    axis.ticks = element_blank()) + 
  coord_cartesian(clip = 'off')
gL <- g.sides + 
  annotate(
    geom = 'text', label = 'Strong (Cat 3) Events ', x = 0, y = 0, 
    family = 'Segoe UI', size = 12/.pt) + 
  theme(
    axis.title.y = element_text(color = NA),
    axis.text.y = element_text(color = NA), 
    axis.ticks.y = element_line(color = NA),
    plot.margin = margin(5,5,5,5))
gR <- g.sides + 
  annotate(
    geom = 'text', label = 'Exceptional (Cat 5) Events ', x = 0, y = 0, 
    family = 'Segoe UI', size = 12/.pt, color = 'black') + 
  theme(
    axis.text.y = element_text(color = NA), 
    axis.ticks.y = element_line(color = NA),
    plot.margin = margin(5,10,5,5))
gT <- g.sides + 
  annotate(
    geom = 'text', label = 'Impactful', x = 0, y = 0, angle = 90,
    family = 'Segoe UI', size = 12/.pt) + 
  ggtitle(label = waiver(), subtitle = 'x') + 
  theme(
    axis.title.x = element_text(color = NA),
    axis.text.x = element_text(color = NA), 
    axis.ticks.x = element_line(color = NA),
    plot.margin = margin(5,5,5,5),
    plot.subtitle = element_text(color = NA))
gB <- g.sides + 
  annotate(
    geom = 'text', label = 'Non-Impactful', x = 0, y = 0, angle = 90,
    family = 'Segoe UI', size = 12/.pt) + 
  theme(
    axis.text.x = element_text(color = NA), 
    axis.ticks.x = element_line(color = NA),
    plot.margin = margin(5,5,5,5))

plot_grid(
  NULL, gL, gR, 
  gT, gTL, gTR, 
  gB, gBL, gBR, 
  nrow = 3, rel_widths = c(1,6.15,6), rel_heights = c(1,8,8.4), axis = 'tl',
  labels = c('', '', '', '', '(a)', '(c)', '', '(b)', '(d)'), label_fontfamily = 'Segoe UI', label_size = 12,
    label_x = 0.8, label_y = 0.8)
ggsave('_figures/fig05_prcpevents.png', width = 12, height = 12, units = 'cm', dpi = 600)

```


# $f(HC)$

This component model represents the distribution of potential antecedent hydrologic conditions.
In this implementation we are using soil moisture as a proxy for antecedent hydrologic conditions.
Soil moisture is measured as the equivalent height of water (mm) in the top meter of the subsurface. 

## Fit lognormal distribution to soil moisture

We found that soil moisture records in the historic catalog were well represented by a lognormal distribution. 
The parameters of the distribution are displayed below.

```{r results = 'hide'}
## load antecedent hydrologic condition function(s)
source('_scripts/3_HC/HC.R')

## fit lognormal distribution to soil moisture records in the historic catalog 
fit_soilmoisture(catalog)

## report parameters of lognormal distribution
```

```{r echo = FALSE}
fit.sm %>% 
  t %>% as.data.frame %>% 
  gt %>% 
  fmt_number(c('meanlog', 'sdlog'), n_sigfig = 3) %>% 
  cols_label('meanlog' = 'Lognormal Mean', 'sdlog' = 'Lognormal Std. Dev.') %>% 
  tab_header(title = 'Soil Moisture Parameters') %>% 
  tab_options(heading.background.color = '#d9d9d9', 
              column_labels.background.color = '#f2f2f2')

```

## Compare observed vs. simulated values

We now take a deeper dive into the February 2019 event. 
We calculate the percentile of the February 2019 antecedent soil moisture within the observed lognormal distribution.

```{r include = FALSE}
## subset case study events to only February 2019 event
feb2019 <- casestudy[4,]

## find percentile of February 2019 event
plnorm(feb2019$sm, meanlog = fit.sm[1], sdlog = fit.sm[2])

```

# $f(Q|PRCP, HC)$

The next component model estimates streamflow ($Q$) as a function of precipitation ($PRCP$) and soil moisture ($HC$). 
From Equation 4 in the paper we know that $Q$ is a function of three parameters.
These are: $Q_p$, peak streamflow; $t_p$, time to peak streamflow; and $m$, a unitless shape parameter.
We discuss each of these in more detail. 

## $Q_p$

### Fit peak streamflow regression model

In order to estimate $Q_p$, we first calculated runoff $R$ using the curve number method, then performed an ordinary least squares regression to predict $Q_p$ as a function of runoff and precipitation using the equation below: 

$$ Q_{p,i} = \beta_0 + \beta_1 (PRCP_i) + \beta_2 (R_i) + \beta_3 (PRCP_i:R_i) + \sigma_i $$ 

Similar to the precipitation model, the uncertainty $\sigma_i$ is once again represented by a mixture model, with 90\% of errors based on the bulk distribution and 10\% of errors based on the 10\% most extreme AR events in the historic catalog.
Model coefficients are shown below.

```{r results = 'hide'}
## load streamflow functions(s)
source('_scripts/4_Q/Q.R')

## fit peak streamflow regression
fit_Qp(catalog)

## display fitted model values
```

```{r echo = FALSE}
model.Qp$coefficients %>% 
  t %>% as.data.frame %>% 
  gt %>% 
  fmt_number(columns = c(`(Intercept)`, precip_mm, runoff_mm, `precip_mm:runoff_mm`), n_sigfig = 3) %>% 
  cols_label(
    `(Intercept)` = 'Intercept',
    precip_mm = 'Precipitation', 
    runoff_mm = 'Runoff', 
    `precip_mm:runoff_mm` = 'Precipitation * Runoff') %>% 
  tab_header(title = 'Peak Streamflow Regression Coefficients') %>% 
  tab_options(heading.background.color = '#d9d9d9', 
              column_labels.background.color = '#f2f2f2')

```

### Assess distribution fit

We follow the same process as the precipitation component model to fit and validate this equation. 
We present both a quantile plot for visual inspection in Figure 6(a) and a formal two-sample K-S test to validate the fit of the overall peak streamflow distribution as compared to the historic catalog. 

```{r results = 'hide', echo = FALSE}
## fit lognormal distribution to time to peak streamflow records in the historic catalog 
fit_tp(catalog)

```

```{r}
## generate one stochastic realization of Qp for every event in the historic catalog
runoff.qq <- fit_generate_runoff(
  precip = catalog %>% 
    transmute(n.AR = 1:nrow(.), n.precip = 1, n.hc = 1, IVT_max, duration, precip_mm, sm), 
  catalog = catalog, probabilistic = TRUE)
hydro.qq <- generate_hydrograph(
  runoff = runoff.qq, 
  model.Qp = model.Qp, se.Qp = se.Qp, fit.tp = fit.tp, 
  probabilistic = TRUE) %>% 
  rename(Qp_sim = Qp_m3s) %>% 
  left_join(
    catalog %>% 
      transmute(n.AR = 1:nrow(.), n.precip = 1, n.hc = 1, n.runoff = 1, n.hydro = 1, Qp_obs = Qp_m3s), 
            by = c('n.AR', 'n.precip', 'n.hc', 'n.runoff', 'n.hydro'))
hydro.max <- max(c(max(hydro.qq$Qp_obs), max(hydro.qq$Qp_sim)))

## plot panel 6(a): quantile plot of observed vs. simulated peak streamflow for the historic catalog
```

```{r fig6a, echo = FALSE}
g7 <- ggplot(hydro.qq) + 
  geom_point(aes(x = sort(Qp_obs), y = sort(Qp_sim)), size = 0.75) + 
  geom_parity() + 
  scale_x_continuous(
    expression(paste('Observed ', Q[p], ' Quantile (', m^{3}, s^{-1}, ')')), 
    expand = expansion(mult = c(0, 0.05)), limits = c(NA, hydro.max), labels = comma) + 
  scale_y_continuous(
    expression(paste('Simulated ', Q[p], ' Quantile (', m^{3}, s^{-1}, ')')), 
    expand = expansion(mult = c(0, 0.05)), limits = c(NA, hydro.max), labels = comma)
if (!publish) g7

```

```{r}
## determine d.crit, the value of the 95% confidence threshold
d.crit <- 1.628 * sqrt(2/nrow(catalog))

## calculate the K-S statistic for 100 simulations
n <- 100
cl <- parallel::makeCluster(num_cores)
registerDoSNOW(cl)
ks.value <- 
  foreach (i = 1:n, 
    .combine = 'c', .packages = c('pracma', 'fitdistrplus', 'tidyverse'), 
    .export = c('fit_generate_runoff', 'generate_hydrograph')) %dopar% {
      ## generate one realization of peak streamflow
      runoff.ks <- fit_generate_runoff(
        precip = catalog %>% 
          transmute(n.AR = 1:nrow(.), n.precip = 1, n.hc = 1, 
                    IVT_max, duration, precip_mm, sm), 
        catalog = catalog, probabilistic = TRUE)
      hydro.ks <- generate_hydrograph(
        runoff = runoff.ks, 
        model.Qp = model.Qp, se.Qp = se.Qp, fit.tp = fit.tp, 
        probabilistic = TRUE)
      ## create a dataframe of sorted values 
      sorted <- data.frame(
        Qp.obs = sort(catalog$Qp_m3s),
        Qp.sim = sort(hydro.ks$Qp_m3s)+4) %>% #add in baseflow
        mutate(p = (1:nrow(.))/(nrow(.)+1))
      ## find the maximum distance between the observed CDF and simulated CDF
      data.frame(
        Qp = seq(
          sorted %>% select(-p) %>% apply(2, min) %>% max, 
          sorted %>% select(-p) %>% apply(2, max) %>% min, 
          length.out = 1000)) %>% 
        mutate(p.obs = interp1(x = sorted$Qp.obs, y = sorted$p, xi = Qp)) %>%
        mutate(p.sim = interp1(x = sorted$Qp.sim, y = sorted$p, xi = Qp)) %>% 
        mutate(d = abs(p.obs-p.sim)) %>% 
        mutate(ks = d/d.crit) %>% 
        pull(ks) %>% max
  }
stopCluster(cl)

## report K-S statistic
```

```{r echo = FALSE}
mean(ks.value) %>% as.data.frame %>% 
  setNames('Mean K-S Statistic') %>% 
  gt %>% 
  fmt_number(`Mean K-S Statistic`, decimals = 3) %>% 
  tab_options(column_labels.background.color = '#f2f2f2')

```

```{r include = FALSE}
# ## plot distribution of K-S statistic 
# ggplot() + 
#   geom_histogram(aes(x = ks.value, y = ..density..), 
#     color = 'black', fill = 'grey90', bins = sqrt(length(ks.value))) + 
#   geom_vline(xintercept = 1, linetype = 'dashed', size = 1) + 
#   scale_x_continuous('Kolmogorov-Smirnov Statistic') + 
#   scale_y_origin('Probability of Occurrence')
# 
# ## prove that this method is better than the default unit conversion
# R2(
#   catalog$runoff_mm * (readNWISsite(11463500)$drain_area_va * 1609.344^2) / catalog$duration,
#   catalog$Qp_m3s)
# R2(predict(model.Qp), catalog$Qp_m3s)

```

The test statistic is still under 1, so once again this regression model is sufficient to accurately represent the peak streamflow distribution in the historic catalog.

## $t_p$ 

Like the antecedent soil moisture, records of time to peak streamflow $t_p$ in the historic catalog were found to be well represented by a lognormal distribution. 
The parameters of the distribution are displayed below, and the empirical vs. modeled distribution is shown in Figure 6(b).

```{r results = 'hide'}
## fit lognormal distribution to time to peak streamflow records in the historic catalog 
fit_tp(catalog)

## report parameters of lognormal distribution
```

```{r echo = FALSE}
fit.tp %>% 
  t %>% as.data.frame %>% 
  gt %>% 
  fmt_number(c('meanlog', 'sdlog'), n_sigfig = 3) %>% 
  cols_label('meanlog' = 'Lognormal Mean', 'sdlog' = 'Lognormal Std. Dev.') %>% 
  tab_header(title = 'Time to Peak Streamflow Parameters') %>% 
  tab_options(heading.background.color = '#d9d9d9', 
              column_labels.background.color = '#f2f2f2')

```

```{r}
## plot panel 6(b): observed vs. simulated time to peak streamflow
```

```{r fig6b, echo = FALSE}
g6 <- 
  data.frame(dx = seq(0, 60, length.out = 1e3)) %>% 
  mutate(fit = dlnorm(dx, meanlog = fit.tp[1], sdlog = fit.tp[2])) %>% 
  ggplot() + 
  geom_histogram(
    data = catalog, 
    aes(x = tp_hrs, y = ..density.., fill = 'Observed \nCatalog'),
    color = 'black', size = 0.25, key_glyph = draw_key_blank) + 
  geom_line(aes(x = dx, y = fit, size = 'Simulated \nDistribution')) + 
  geom_vline(xintercept = feb2019$tp_hrs, linetype = 'dashed') + 
  annotate(geom = 'text', 
    x = feb2019$tp_hrs, y = 0.0425, angle = 90, vjust = -0.5,
    label = 'February 2019', family = 'Segoe UI', size = 8/.pt) + 
  scale_fill_manual(values = 'grey90') + 
  scale_size_manual(values = 0.5) + 
  scale_x_origin(expression('Time to Peak Streamflow,' ~ t[p] ~ '(h)')) +
  scale_y_origin('Probability of Occurrence') + 
  guides(fill = guide_legend(order = 1, override.aes = list(size = 0.025, color = 'pink')),
         color = guide_legend(order = 2)) +
  annotate('rect', xmin = 49.25, xmax = 53.9, ymin = 0.0345, ymax = 0.03875, 
           fill = 'grey90', color = 'black', size = 0.25) + 
  theme(legend.title = element_blank(),
        legend.margin = margin(1, 0, 1, 0, unit = 'mm'),
        legend.spacing.y = unit(0.1, 'mm'),
        legend.key.width = unit(4, 'mm'),
        legend.spacing.x = unit(1, 'mm'),
        legend.background = element_rect(fill = NA),
        # legend.key = element_rect(color = 'black'),
        plot.margin = margin(5.5, 25, 5.5, 5.5),
        legend.position = c(0.85, 0.5))
if (!publish) g6

```

```{r include = FALSE}
## find percentile of February 2019 event
plnorm(feb2019$tp_hrs, meanlog = fit.tp[1], sdlog = fit.tp[2])

```

## $m$

A value of $m=4$ was chosen based on an inspection of observed hydrographs for the Russian River in Sonoma County and on the recommendation found in the National Engineering Handbook.

## Plot real vs. simulated streamflow hydrograph

After validating the estimation of $Q_p$, $t_p$, and $m$, we now compare the observed vs. simulated streamflow timeseries for the 2019 case study event.
We generate simulated realizations of streamflow given the real precipitation, then compare the realizations to the true observed hydrograph.

### Load observed streamflow hydrographs for the February 2019 event

We start by finding the true hourly precipitation and 15-minute streamflow hydrograph for the February 2019 event for comparison. 
For this case study, streamflow was measured at USGS gage 11463500, which is at the inlet to the study area.  

```{r}
## download observed hourly precipitation for the February 2019 event
# https://www.ncei.noaa.gov/products/land-based-station/cooperative-observer-network
hourly <- read.csv('_data/USC00048885.csv') %>% 
  filter(ymd(DATE) >= ymd(feb2019$start_day) - days(14) & 
           ymd(DATE) <= ymd(feb2019$end_day) + days(14)) %>% 
  select(DATE, starts_with('HR')) %>% 
  select(DATE, ends_with('Val')) %>% 
  pivot_longer(cols = -DATE) %>% 
  mutate(hour = name %>% str_remove('HR') %>% str_remove('Val') %>% toNumber) %>% 
  mutate(datetime = ymd(DATE) + hours(hour)) %>% 
  filter(value > 0) %>% 
  mutate(value = value/100*25.4) #convert from hundreds of an inch to mm

## define parameters & statistics to request from USGS streamgage service
param <- c('00060', '00065')
names(param) <- c('discharge_cfs', 'gageht_ft')
statcode <- c('00001', '00002', '00003', '00008')
names(statcode) <- c('max', 'min', 'mean', 'median')

## download observed gauge information for the February 2019 event
flow <- readNWISdata(
  sites = 11463500, parameterCd = param, 
  startDate = ymd(feb2019$start_day) - days(1), 
  endDate = ymd(feb2019$end_day) + days(5), 
  service = 'iv', tz = 'America/Los_Angeles') %>% 
  renameNWISColumns

```

### Generate simulated realizations of streamflow parameters

We generate 1,000 realizations of peak streamflow $Q_p$ and time to peak streamflow $t_p$. 
The hydrograph shape parameter $m$ is held constant. 

```{r}
## load observed precipitation for the February 2019 event
precip <- feb2019 %>%
  transmute(n.AR = 1, n.precip = 1, IVT_max, duration, precip_mm)

## generate probabilistic realizations of HC (soil moisture) for the 2019 event
precip <- generate_soilmoisture(precip, fit.sm, probabilistic = TRUE, n.hc = 1e3)

## generate probabilistic realizations of R (runoff) for the 2019 event
runoff <- 
  fit_generate_runoff(
    precip = precip, 
    catalog = catalog, 
    probabilistic = TRUE, 
    n.runoff = 1)

## generate probabilistic realizations of Q (streamflow) for the 2019 event 
hydrograph <-
  generate_hydrograph(
    runoff = runoff,
    model.Qp = model.Qp, se.Qp = se.Qp, fit.tp = fit.tp, 
    probabilistic = TRUE,
    n.hydro = 1)

```

### Generate simulated hydrographs for the 2019 event

Finally, we use our simulated parameters to construct synthetic hydrographs for the February 2019 event. 
These hydrographs are aggregated and the overall statistics of the timeseries distribution are shown in Figure 6(c).

```{r}
## set constants
baseflow <- 3
simlength <- 10 * 24 * 3600
t <- seq(0, simlength, 360)
m <- 4

## create synthetic streamflow timeseries records
maxflow <- which.max(flow$Flow_Inst)
num_cores <- 5
cl <- parallel::makeCluster(num_cores)
registerDoSNOW(cl)
flow.sim <- 
  foreach (i = 1:nrow(hydrograph), 
    .packages = 'lubridate') %dorng% {
    Qp <- hydrograph$Qp_m3s[i]
    tp <- hydrograph$tp_hrs[i]*60^2 #seconds
    q <- apply(cbind(exp(m*(1-t/tp)) * (t/tp)^m * Qp, rep(baseflow, length(t))), 1, max)
    sim <- data.frame(t = lubridate::now() + seconds(t), q = q)
    dt <- sim[which.max(sim$q), 't'] - flow[maxflow, 'dateTime']
    sim$t <- sim$t - dt
    sim
  } 
stopCluster(cl)

t.min <- flow.sim %>% lapply(function(x) Min(x$t)) %>% do.call('c', .) %>% Min
t.max <- flow.sim %>% lapply(function(x) Max(x$t)) %>% do.call('c', .) %>% Max
flow.sim <- flow.sim %>%
  lapply(function(x) {
    right_join(x, data.frame(t = seq(t.min, t.max, '6 min')), by = 't') %>% 
      arrange(t) %>% pull(q)
  }) %>% 
  do.call(cbind, .) %>% 
  as.data.frame %>% 
  mutate(
    t = flow.sim[[1]] %>% 
      right_join(data.frame(t = seq(t.min, t.max, '6 min')), by = 't') %>% 
      arrange(t) %>% pull(t)) %>% 
  select(t, 1:last_col(1))
flow.sim[is.na(flow.sim)] <- baseflow

## find USGS flood stage for gage 11463500
# https://waterdata.usgs.gov/nwis/dv?referred_module=sw&site_no=11463500
floodstage <- 39.7 

## convert to m3/s using the USGS rating curve for gage 11463500
floodflow <- readNWISrating(siteNumber = 11463500, type = 'exsa') %>% 
  mutate(m3s = DEP / mft^3) %>% 
  filter(INDEP == floodstage) %>% pull(m3s)

## calculate statistics of synthetic streamflow timeseries records
sequence <- flow.sim$t
flow.matrix <- flow.sim %>% select(-t) %>% as.matrix %>% unname
flow.df <- data.frame(t = sequence) %>% 
  mutate(min = apply(flow.matrix, 1, Min), 
         q05 = apply(flow.matrix, 1, function(x) quantile(x, 0.05, na.rm = TRUE)),
         q25 = apply(flow.matrix, 1, function(x) quantile(x, 0.25, na.rm = TRUE)),
         med = apply(flow.matrix, 1, function(x) median(x, na.rm = TRUE)),
         mean = apply(flow.matrix, 1, Mean), 
         q75 = apply(flow.matrix, 1, function(x) quantile(x, 0.75, na.rm = TRUE)),
         q95 = apply(flow.matrix, 1, function(x) quantile(x, 0.95, na.rm = TRUE)), 
         max = apply(flow.matrix, 1, Max)) %>% 
  mutate(min = ifelse(is.infinite(min), NA, min),
         mean = ifelse(is.nan(mean), NA, mean), 
         max = ifelse(is.infinite(max), NA, max))

## plot panel 6(c): observed vs. simulated hydrograph for the 2019 event
```

```{r fig6c, echo = FALSE}
g8 <- ggplot(flow.df) + 
  geom_ribbon(aes(x = t, ymin = 2003 - q05, ymax = 2003 - q95, fill = '90th p.')) + 
  geom_ribbon(aes(x = t, ymin = 2003 - q25, ymax = 2003 - q75, fill = '50th p.')) +
  geom_line(aes(x = t, y = 2003 - med, fill = 'Median'), color = 'grey25') + 
  scale_fill_manual('Simulated \nStreamflow',
    breaks = c('Median', '50th p.', '90th p.'),
    labels = c('Median', '50% P.I.', '90% P.I.'),
    values = c('grey25', 'grey70', 'grey90')) + 
  geom_line(data = flow, 
    aes(x = ymd_hms(dateTime, tz = 'America/Los_Angeles'), y = 2000 - Flow_Inst/mft^3, 
        color = 'February 2019'), size = 0.75, linetype = 'dashed') + 
  geom_col(data = hourly %>% filter(value > 1),
    aes(x = datetime, y = value*50), 
    fill = roma.colors[5], color = roma.colors[5], size = 0.25) +
  scale_y_reverse(
    name = expression(paste('Observed Precipitation (mmâ‹…', h^{-1}, ')')),
    labels = comma_format(scale = 0.02),
    expand = expansion(mult = c(0,0)),
    sec.axis = sec_axis(~ 2000 - .,
      name = expression(paste('Streamflow (', m^{3}, s^{-1}, ')')),
      labels = comma)) + 
  theme(axis.title.y.left = element_text(color = roma.colors[5]),
        axis.text.y.left = element_text(color = roma.colors[5]),
        axis.line.y.left = element_line(color = roma.colors[5]),
        axis.ticks.y.left = element_line(color = roma.colors[5])) +
  scale_color_manual('Observed \nStreamflow', values = 'black') + 
  geom_hline(yintercept = 2000 - floodflow, color = roma.colors[1]) + 
  annotate('text', label = 'Flood Flow', 
           x = ymd_hms('2019-03-01 8:00:00PM'), y = 2000 - floodflow, 
           family = 'Segoe UI', size = 8/.pt, color = roma.colors[1], vjust = -0.5) +
  scale_x_datetime('Date',
    limits = c(ymd_hms('2019-02-24 12:00:00PM', tz = 'America/Los_Angeles'),
               ymd_hms('2019-03-03 12:00:00PM', tz = 'America/Los_Angeles')),
    date_breaks = 'day', date_labels = '%b %d', expand = c(0,0), 
    sec.axis = dup_axis()) + 
  theme(axis.title.x.top = element_blank(),
        axis.text.x.top = element_blank(),
        axis.ticks.x.top = element_blank(),
        axis.line.x.top = element_line(color = roma.colors[5])) +
  guides(colour = guide_legend(override.aes = list(size = 0.5))) +
  theme(legend.margin = margin(1, 0, 1, 0, unit = 'mm'),
        legend.spacing.y = unit(0.75, 'mm'),
        legend.key.width = unit(4, 'mm'),
        legend.spacing.x = unit(0.5, 'mm'),
        axis.text.x = element_text(angle = 45, hjust = 1)) + 
  theme(plot.margin = margin(5.5, 45, 5.5, 16))
if (!publish) g8

```

```{r}
## find simulated quantile of observed peak streamflow
peak.sim <- flow.matrix %>% apply(2, max)
peak.obs <- max(flow$Flow_Inst)/mft^3
p.peak <- sum(peak.sim <= peak.obs) / length(peak.sim)

## define length of observed floodwave
floodwave <- flow %>% 
  mutate(diff = c(0, abs(diff(Flow_Inst)))) %>% 
  mutate(pass = diff > 50, count = 0)
for (i in 5:nrow(floodwave)) floodwave$count[i] <- sum(floodwave$pass[(i-4):i])
floodwave <- floodwave %>% 
  slice(which(count>0)[1]:nrow(.)) %>% 
  slice(1:which(count==0)[1])
# ggplot(floodwave) + 
#   geom_line(aes(x = dateTime, y = Flow_Inst))

## find simulated quantile of observed flood wave duration
dur.sim <- apply(flow.matrix>3, 2, sum) / 10 #hours
dur.obs <- difftime(max(floodwave$dateTime), min(floodwave$dateTime), units = 'hours') %>% as.numeric
p.dur <- sum(dur.sim <= dur.obs) / length(dur.sim)

## report quantile values
```

```{r echo = FALSE}
data.frame(p.peak, p.dur) %>% 
  gt %>% 
  fmt_percent(c(p.peak, p.dur), decimals = 1) %>% 
  cols_label(
    p.peak = 'Peak Streamflow',
    p.dur = 'Flood Wave Duration') %>% 
  tab_header(title = 'Simulated Quantiles of Observed Values') %>% 
  tab_options(heading.background.color = '#d9d9d9', 
              column_labels.background.color = '#f2f2f2')

```

```{r fig6, include = publish, echo = FALSE}
## generate figure 6
plot_grid(
  plot_grid(
    g7 + theme_bw_custom(), g6, 
    nrow = 1, axis = 'b', align = 'h',
    labels = c('(a)', '(b)'), label_fontfamily = 'Segoe UI', label_size = 12,
    label_x = c(0.25, 0.75), label_y = 0.925),
  g8, nrow = 2, labels = c('', '(c)'), rel_heights = c(5,6),
  label_fontfamily = 'Segoe UI', label_size = 12,
  label_x = 0.6, label_y = 0.9)
ggsave('_figures/fig06_hydrograph.png', width = 12, height = 12, units = 'cm')

```


# $f(INUN|Q)$

This component model estimates inundation ($INUN$) as a function of the streamflow hydrograph ($Q$).
This step includes a large increase in memory and computing requirements compared to the other component models, because each streamflow hydrograph (represented by three parameters) is transformed into inundation heights at thousands of building locations within the study area.

The model used in this implementation is also much more complex than any of the other component models thus far.
We used the hydrodynamic solver LISFLOOD as the base model to estimate inundation heights as a function of streamflow hydrographs. 
The fit of the LISFLOOD model is explained in the `5a_run_lisflood` and `5b_run_bestfit` folders.
We then applied a low-dimensional surrogate model to rapidly estimate inundation based on a pre-computed bank of LISFLOOD inundation maps, as explained in the `5d_populate_grid` and `5e_fit_surrogate` folders.
We refer the user to these locations for more information about the fit and validation of the inundation component model.
Here we focus on the results of the 2019 event case study, which are found in the `5c_run_2019event` folder.

For the 2019 event, we compared simulated results to the "observed" inundation in three ways. 
The first approach was to assess how well we were able to reproduce downstream hydrographs. 
This is a "channel-focused" method that looks at the amount of water in the river at various points in time and space.
The second approach is a "floodplain-focused" method that compares the number of dry vs. wet cells between the observed and simulated inundation maps. 
The third and final approach is an "impact-focused" method that compared the number of inundated buildings. 
Each of these approaches is explained in more detail below.

## Validate river channel 

### Load observed downstream hydrograph data

We first identify the gages that are downstream of the study area inlet and that have available either stage or discharge data for the 2019 storm.
The locations of these gages are shown in the Figure 7(a) below.
ID labels for each gage were added with the image editing software Inkscape.
We then load the 2019 event hydrographs at each of these gages to use as the observed case in our case study comparison.

```{r}
## identify gages of interest based on geography
gages <- whatNWISsites(stateCd = '06', countyCd = '097') %>% 
  filter(grepl('RUSSIAN', station_nm)) %>% 
  filter(str_length(site_no) == 8) %>% 
  filter(site_no != 11463500)

## load observed discharge & stage height data
flow.obs <- readNWISdata(
  sites = gages$site_no, 
  parameterCd = param, 
  startDate = ymd(feb2019$start_day) - days(30), 
  endDate = ymd(feb2019$end_day) + days(7), 
  service = 'iv', tz = 'America/Los_Angeles') %>% 
  renameNWISColumns %>% 
  filter(!is.na(Flow_Inst) | !is.na(GH_Inst))

## filter out gages with no data
gages <- gages %>% 
  filter(site_no %in% unique(flow.obs$site_no)) %>% 
  arrange(site_no)

## plot panel 7(a): map of gages of interest within the study area
```

```{r fig7a, echo = FALSE}
readNWISsite(siteNumbers = c(11463500, gages$site_no[-2])) %>% 
  st_as_sf(coords = c('dec_long_va', 'dec_lat_va'), crs = 4269) %>% 
  st_transform(6417) %>% 
  ggplot() + 
  geom_sf(data = st_union(sonoma), color = 'grey50', fill = 'grey95') + 
  geom_sf(data = aoi, fill = 'grey50', alpha = 0.1, color = 'black') + 
  geom_sf(data = russian %>% st_transform(6417) %>% st_crop(sonoma), 
          color = 'grey30', size = 0.75) + 
  geom_sf(aes(color = factor(site_no)), size = 2) + 
  scale_color_manual('USGS Gauge', guide = FALSE,
                     values = c('black', roma.colors[-3])) + 
  theme_void() +
  theme(text = element_text(family = 'Segoe UI'),
        plot.title = element_text(family = 'Segoe UI Semibold'))
ggsave('_figures/fig07/fig07_map.png', width = 6, height = 8, units = 'cm')

```

### Load simulated downstream hydrograph data

We used the observed streamflow hydrograph at USGS gage 11463500 as input to LISFLOOD to generate simulated hydrographs at each of the gages of interest.
The LISFLOOD model was run using Sherlock, Stanford's high-performance computing cluster.

```{r}
## load simulated stage data
stage <-
  read.table(
    '_scripts/5_INUN/fit_inundation/5c_run_2019event/results/casestudy.stage', skip = 11) %>%
  setNames(c('t', gages$site_no)) %>%
  pivot_longer(cols = -t, names_to = 'site_no', values_to = 'h') %>%
  mutate(dateTime = flow.obs$dateTime[1] + seconds(t)) %>%  # 
  right_join(flow.obs %>% select(dateTime, site_no, GH_Inst), by = c('dateTime', 'site_no')) %>% 
  rename(h.obs = GH_Inst, h.sim = h) %>% 
  mutate(h.obs = h.obs/mft)

```

### Plot observed vs. simulated hydrographs at gages of interest 

We use the stage data output from LISFLOOD, then manually correct the vertical datums of the gages to be in NAVD88 (Geoid 12A), which is the vertical datum of the LISFLOOD elevation file. 
We then plot observed vs. simulated stage height for the duration of the 2019 event, which is Figure 7(b) in the paper.

```{r}
## calculate gage elevation from LISFLOOD DEM
bed <- 
  raster('_scripts/5_INUN/fit_inundation/5c_run_2019event/results/casestudy_SGC_bedZ.asc',
         crs = projection(aoi))
bed[][bed[]>1e9] <- NA
gages.elev <- gages %>%
  st_as_sf(coords = c('dec_long_va', 'dec_lat_va'), crs = 4269) %>%
  st_transform(6417) %>%
  mutate(lisflood_m = raster::extract(bed, ., small = TRUE)) %>%
  mutate(site_no = toNumber(site_no)) %>% 
  left_join(readNWISsite(gages$site_no) %>% select(site_no, alt_va, alt_datum_cd),
            by = 'site_no')

## get the vertical datum conversion from USGS -> LISFLOOD
## (LISFLOOD/SonomaVegMap is in NAVD88 (Geoid 12A), USGS varies)
gages.elev <- gages.elev %>%
  mutate(datum_conversion_m = c(0, NA, 0.873, 0.854, 0.863)) %>%
  mutate(usgs_m = alt_va/mft + datum_conversion_m)

## plot panel 7(b): timeseries of observed vs. simulated stage height at gages of interest
```

```{r fig7b, echo = FALSE}
stage.plot <- stage %>% 
  mutate(site_no = toNumber(site_no)) %>% 
  filter(site_no != 11463980) %>% 
  left_join(gages.elev, by = 'site_no') %>% 
  mutate(h.obs = h.obs+usgs_m-lisflood_m) %>% 
  filter(dateTime >= ymd_hms('2019-02-23 12:00:00AM') &
           dateTime <= ymd_hms('2019-03-04 12:00:00AM'))

ggplot(stage.plot) + 
  geom_line(
    aes(x = dateTime, y = h.obs, linetype = 'Observed', 
        color = factor(site_no)), size = 0.5) +
  geom_line(
    aes(x = dateTime, y = h.sim, linetype = 'Simulated', 
        color = factor(site_no)), size = 0.5) + 
  facet_wrap(~site_no, nrow = 4,
    labeller = labeller(site_no = function(x) paste('USGS', x))) + 
  scale_linetype_manual('Data Type', values = c(2,1)) + 
  scale_color_manual('USGS Gauge', guide = FALSE, values = roma.colors[-3]) + 
  scale_x_datetime('Date', labels = function(z) gsub("^0", "", strftime(z, "%m/%d")),
    date_breaks = 'day', minor_breaks = 'day') +
  scale_y_continuous('Water Surface (m)', limits = c(0, NA), expand = expansion(mult = c(0, 0.1))) + 
  guides(linetype = guide_legend(override.aes = list(size = 0.5))) +
  theme_bw_custom() + 
  theme(strip.background = element_blank(),
        strip.text = element_text(color = 'black', size = 8),
        legend.position = 'bottom',
        legend.margin = margin(-5, 0, 0, 0),
        legend.key.width = unit(5, 'mm'),
        legend.spacing.x = unit(1, 'mm'),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
ggsave('_figures/fig07/fig07_timeseries.png', width = 6, height = 12, units = 'cm')

```

## Validate floodplain

For the 2019 event, the "observed" data is not the exact inundation recorded due to this AR, but instead it is the closest-matching inundation map from a series of detailed inundation predictions released by the Sonoma County Permit and Resource Management Department (referred to as the Sonoma GIS map).
The simulated data is the inundation map in the `5c_run_2019event` folder.

### Load "observed" and simulated inundation maps

```{r}
## load "observed" inundation map
source('_data/flood_sonoma/flood_sonoma.R')
flow.obs %>% filter(site_no == 11467002) %>% pull(GH_Inst) %>% max
flood.sonoma <- flood_sonoma(45)*0.64 + flood_sonoma(46)*0.36

## load simulated inundation map
lisflood <- 
  raster('_scripts/5_INUN/fit_inundation/5c_run_2019event/results/casestudy.max',
         crs = projection(aoi)) %>% 
  overlay(dem.hydro, fun = function(x,y) ifelse(y < 1, NA, x))
lisflood.df <- lisflood %>% raster.df %>% filter(value > 0)

## match raster extents
flood.df <- flood.sonoma %>%
  projectRaster(lisflood) %>%
  raster.df %>% filter(value > 0)

```

### Plot "observed" vs. simulated inundation maps

We compare these two maps on a binary basis and calculate how often our simulated map is able to correctly reproduce wet vs. dry cells compared to the Sonoma GIS "observed" map.
Figure 7(c) below shows the spatial distribution of wet vs. dry accuracy within the extent of the Sonoma GIS model, which is indicated by the dotted line. 

```{r}
## define the spatial extent of the Laguna de Santa Rosa 
## (not included in the Sonoma GIS inundation map --> remove from validation statistics)
laguna <- aoi %>%
  st_cast('POINT') %>% st_coordinates %>%
  .[1:3,] %>%
  rbind(c(1935000, 598500)) %>%
  rbind(c(1930000, 598500)) %>%
  rbind(c(1924500, 593000)) %>%
  rbind(c(1924500, 579500)) %>%
  rbind(.[1,]) %>%
  data.frame %>%
  st_as_sf(coords = c('X', 'Y'), crs = st_crs(6417)) %>%
  st_combine %>%
  st_cast('POLYGON')
laguna <- flood.sonoma %>%
  extent %>% as('SpatialPolygons') %>% st_as_sf %>%
  st_set_crs(crs(flood.sonoma)) %>% st_transform(6417) %>%
  st_crop(laguna, .)
laguna.raster <- laguna %>% as('Spatial') %>% rasterize(lisflood)

## plot panel 7(c): map of inundation prediction accuracy
```

```{r fig7c, echo = FALSE}
flood.map <- flood.sonoma %>%
  projectRaster(lisflood) %>%
  overlay(lisflood, fun = function(x,y) {
    ifelse(x > 0 & y > 0, 0, ifelse (x > 0 & y <= 0, -1, ifelse(x <= 0 & y > 0, 1, NA)))})
ggplot() + 
  geom_sf(data = sonoma %>% st_union %>% st_crop(aoi),
    color = 'grey50', fill = 'grey95') + 
  geom_sf(data = aoi, color = 'black', fill = NA) + 
  geom_raster(data = lisflood.df, aes(x=x, y=y), fill = 'grey70', alpha = 0.5) + 
  geom_raster(
    data = flood.map %>% mask(laguna.raster) %>% 
      raster.df %>% filter(!is.na(value)),
    aes(x=x, y=y, fill = factor(value))) +
  geom_sf(data = laguna, fill = NA, color = 'black', linetype  = 'dotted') +
  scale_fill_manual(
    'Legend', values = c(roma.colors[4], 'black', roma.colors[2]),
    labels = c('False \nNegative', 'Correct', 'False \nPositive')) +
  annotation_scale(
    width_hint = 0.2, height = unit(0.25, 'cm'), text_cex = 2/3, 
    location = 'tl', pad_x = unit(0.5, 'cm'), pad_y = unit(0.1, 'cm')) +
  scale_y_continuous(expand = expansion(mult = c(0,0))) +
  theme_void() +
  theme(text = element_text(family = 'Segoe UI', size = 8),
        legend.position = 'bottom',
        legend.text = element_text(margin = margin(r = 10)),
        legend.margin = margin(0.1, 0.1, 0.1, 0.1, unit = 'cm'),
        legend.title = element_blank())
ggsave('_figures/fig07/fig07_floodmap.png', width = 6, height = 9, units = 'cm')

```

### Calculate accuracy of "observed" vs. simulated wet/dry prediction

We chose three wet vs. dry metrics: hit rate (which penalizes false negatives), false alarm ratio (which penalizes false positives), and the critical success index (which balances over- vs. under-prediction). 
These metrics were used by Wing et al. (2017) and First Street Foundation for fitting a nationwide flood inundation model.
More information on the metrics can be found in the `5a_run_bestfit` folder.

```{r}
## calculate accuracy statistics based on confusion matrix
confusion <- function(x,y) {
  ifelse(x > 0 & y > 0, 0, ifelse (x > 0 & y <= 0, -1, ifelse(x <= 0 & y > 0, 1, NA))) 
}
temp <- flood.sonoma %>% 
  projectRaster(lisflood) %>% 
  overlay(lisflood, fun = function(x,y) confusion(x,y)) %>% 
  overlay(dem, fun = function(x,y) ifelse(y>1, x, NA)) 
temp.laguna <- temp %>% mask(laguna.raster)
tb <- table(temp.laguna[])
hitrate = tb[2] / sum(tb[1:2])
falsealarm = tb[3] / sum(tb[2:3])
fstat = tb[2] / sum(tb)

## report accuracy statistics
```

```{r echo = FALSE}
data.frame(
  'hitrate' = c(unname(hitrate), 1),
  'falsealarm' = c(unname(falsealarm), 0),
  'fstat' = c(unname(fstat), 1)) %>% 
  mutate(temp = c('LISFLOOD', 'Best-Case')) %>% 
  # t %>% as.data.frame %>% 
  gt %>% 
  cols_move_to_start(temp) %>% 
  fmt_percent(c('hitrate', 'falsealarm', 'fstat'), decimals = 1) %>% 
  cols_label(hitrate = 'Hit Rate', falsealarm = 'False Alarm', 
             fstat = 'Critical Success Ratio', temp = '') %>% 
  tab_header(title = 'Floodplain Inundation Accuracy Statistics') %>% 
  tab_options(heading.background.color = '#d9d9d9', 
              column_labels.background.color = '#f2f2f2')
  
```

## Validate number of inundated buildings

The observed vs. comparison statistics presented above consider the entire map with equal importance. 
However, because the density of residential housing is not constant over the study area, these inundation depths do not have equal impacts.
Therefore we also consider the total number of inundated buildings as a final comparison metric.

Here we compare the number of inundated buildings in the "observed" vs. simulated case, but we also have one additional data point to consider.
We described earlier how the "observed" (Sonoma GIS) inundation map is not directly tied to the flooding experienced during the 2019 event. 
News articles following the 2019 event estimated that about 1,900 homes saw at least some level of nonzero inundation, which is information that is directly related to the case study event under consideration. 
We compare that number to the estimated number of inundated buildings both in the "observed" map and in the simulated map, as seen in the table below.

```{r echo = FALSE}
## check number of inundated buildings
buildings.coord <- buildings %>% st_coordinates

## report number of inundation buildings
c(simulated = Sum(terra::extract(rast(flood.map), buildings.coord) >= 0),
  sonoma_gis = Sum(terra::extract(rast(flood.map), buildings.coord) <= 0),
  reported = 1900) %>% 
  t %>% as.data.frame %>% 
  gt %>% 
  fmt_number(c('simulated', 'sonoma_gis', 'reported'), decimals = 0) %>% 
  cols_label(
    simulated = 'LISFLOOD Simulation',
    sonoma_gis = '"Observed" (Sonoma GIS)',
    reported = '2019 Reported Estimate') %>% 
  tab_header(title = 'Number of Inundated Buildings') %>% 
  tab_options(heading.background.color = '#d9d9d9', 
              column_labels.background.color = '#f2f2f2')

```

```{r include = FALSE}
## compare "observed" vs. simulated building inundation heights 

# flood.bldg <- cbind(
#   rast(lisflood) %>% terra::extract(buildings.coord),
#   rast(flood.sonoma %>% projectRaster(lisflood)) %>% terra::extract(buildings.coord)) %>% 
#   setNames(c('sim', 'obs')) %>% 
#   mutate(resid = sim-obs/mft) %>% 
#   cbind(buildings.coord) %>% 
#   filter(!is.na(resid)) %>% 
#   filter(sim>0 | obs>0) %>% 
#   arrange(abs(resid)) %>% 
#   st_as_sf(coords = c('X', 'Y'), crs = 6417)
# flood.bldg <- flood.bldg %>% 
#   mutate(group = case_when(
#     abs(resid) > 15 ~ 'big', 
#     abs(resid) > 5 ~ 'med', 
#     sim == 0 & obs == 0 ~ 'zero',
#     TRUE ~ 'small'))
# ggplot(flood.bldg) +
#   geom_point(aes(x = obs/mft, y = sim)) +
#   scale_x_origin('Sonoma GIS Inundation (m)') + scale_y_origin('LISFLOOD Inundation (m)') +
#   geom_parity() + coord_fixed(clip = 'off')

```

```{r include = FALSE}
## repeat the above plot, but with the surrogate model

# ## get simulated inundation
# source('_scripts/INUN_sherlock.R')
# hydrograph <- casestudy %>% mutate(n.AR = 1, n.precip = 1, n.hydro = 1)
# load('_sensitivity/surrogate/checkpoints/samples.Rdata')
# cl <- parallel::makeCluster(num_cores)
# registerDoSNOW(cl)
# inundation <-
#   generate_inundation(
#     hydrograph = hydrograph,
#     samples = samples,
#     buildings = buildings,
#     probabilistic = TRUE, n.inun = 1e3
#   )
# stopCluster(cl)
# 
# ## get "observed" inundation
# buildings$inun <- unlist(terra::extract(rast(flood.sonoma %>% projectRaster(dem)), buildings.coord))
# 
# ## plot "observed" vs. surrogate model inundation heights
# temp <- inundation %>% do.call(cbind, .)
# data.frame(
#   id = attr(inundation, 'wet.bldg'),
#   sim.05 = apply(temp, 1, function(x) quantile(x, 0.05)),
#   sim.25 = apply(temp, 1, function(x) quantile(x, 0.25)),
#   sim.med = apply(temp, 1, median),
#   sim.75 = apply(temp, 1, function(x) quantile(x, 0.75)),
#   sim.95 = apply(temp, 1, function(x) quantile(x, 0.95))) %>%
#   full_join(buildings %>% st_drop_geometry %>%
#               transmute(id = bldg, obs = inun/mft), by = 'id') %>%
#   ggplot() +
#   geom_segment(aes(x = obs, xend = obs, y = sim.05, yend = sim.95), color = 'grey70') +
#   geom_point(aes(x = obs, y = sim.med)) +
#   scale_x_origin('Sonoma GIS Inundation (m)') + scale_y_origin('Surrogate Model Inundation (m)') +
#   geom_parity() + coord_fixed(clip = 'off')
  
```


# $f(DM|INUN)$

The next component model in the framework is the estimation of building damage ($DM$) as a function of first floor water level.
We have implemented this component model by using depth-damage curves. 
Because of the significant uncertainty in predicting damage as a function of flood depth alone, we use two different depth-damage relationships: one from Hazus-MH and one from Wing et al. (2020).

## Select depth-damage relationships

Hazus-MH uses deterministic, monotonic depth-damage relationships. 
Curves are chosen based on (a) the number of stories and (b) whether or not there is a basement present. 
On the other hand, the Wing et al. (2020) depth-damage relationships only consider depth, but are probabilistic functions represented by the beta distribution. 
A visual comparison of the two curves at different flood heights is included in Figure 8(a) in the paper. 
We refer the user to the paper for a discussion of the merits of each one.

```{r}
## plot panel 8(a): comparison of HAZUS vs. Wing et al. (2020) distributions
```

```{r fig8a, echo = FALSE}
## generate Wing et al. (2020) distributions
dx <- 0.01
beta.dist <- 
  map_dfc(.x = 1:nrow(wing2020), 
    .f = ~dbeta(x = seq(dx, 1-dx, dx), shape1 = wing2020$alpha[.x], 
                shape2 = wing2020$beta[.x])) %>%
    setNames(wing2020$depth_ft) %>% 
    mutate(damage_pct = seq(dx, 1-dx, dx)) %>% 
    pivot_longer(cols = -damage_pct, names_to = 'depth_ft', values_to = 'damage_prob') %>% 
    mutate(depth_ft = toNumber(depth_ft)) 

g13 <- ggplot() + 
  ggridges::geom_density_ridges(
    data = beta.dist,
    aes(x = damage_pct, y = depth_ft, group = depth_ft, height = damage_prob,
        fill = 'Wing et al.'), 
    color = 'grey50', alpha = 0.6, stat = 'identity') + 
  geom_line(
    data = wing2020 %>% rbind(rep(0, 5)), 
    aes(x = mu, y = depth_ft), color = 'grey60', size = 0.75) + 
  geom_point(
    data = wing2020 %>% rbind(rep(0, 5)), 
    aes(x = mu, y = depth_ft), color = 'grey60') + 
  geom_line(
    data = hazus %>% filter(class == '1 N Struct'), 
    aes(x = damage_pct, y = depth_ft, color = 'Hazus-MH'), size = 0.75) + 
  scale_color_manual('', values = 'black') + 
  scale_fill_manual('', values = 'grey70') + 
  scale_x_continuous('Damage Ratio', labels = percent, 
                     expand = expansion(mult = c(0,0))) + 
  scale_y_origin('First Floor Water Depth (m)', breaks = seq(0, 5, 0.5)*mft, 
                 labels = comma_format(accuracy = 0.1, scale = 1/mft)) + 
  coord_flip(xlim = c(0,1), clip = 'off') + 
  theme(legend.position = c(0.8, 0.78), 
        legend.margin = margin(-10, 0, -10, 0))
if (!publish) g13 

```

## Load "observed" damage data

We were unable to identify any direct damage data for the 2019 event. 
Instead we are using safety tags from the Sonoma County Rapid Evaluation Safety Assessment (RESA) that were assigned to buildings immediately after the 2019 event. 
The paper discusses some of the implications and limitations of this proxy.
The table below (Table 2 in the paper) summarizes the number of buildings with nonzero first floor water levels, broken out by the status of the RESA tag.

```{r}
## calculate aggregated tag/safety categories
buildings <- buildings %>% 
  mutate(safety = case_when(
    RESA_Status_GIS == 'Green' ~ 'tagged/safe', 
    RESA_Status_GIS == 'Yellow' ~ 'tagged/unsafe',
    RESA_Status_GIS == 'Red' ~ 'tagged/unsafe',
    TRUE ~ 'untagged')) %>% 
  mutate(safety = factor(safety, levels = c('untagged', 'tagged/safe', 'tagged/unsafe')))

## calculate inundation due to the Sonoma GIS map 
buildings$inun <- 
  terra::extract(rast(flood.sonoma %>% projectRaster(dem)), 
                 st_coordinates(buildings)) %>% unlist

## report number & percent of inundated buildings by safety category
```

```{r tab2, echo = FALSE}
buildings %>% 
  st_drop_geometry %>% 
  group_by(safety) %>% 
  summarize(
    `Number of Inundated Buildings` = Sum(inun>0) %>% comma(accuracy = 1),
    `Number of Total Buildings` = length(inun) %>% comma(accuracy = 1),
    `Percent Inundated` = (Sum(inun>0)/length(inun)) %>% percent(accuracy = 0.01)) %>% 
  column_to_rownames('safety') %>%
  t %>% as.data.frame %>%
  rownames_to_column('temp') %>% 
  gt %>% 
  fmt_markdown(temp) %>% 
  cols_label(
    'temp' = '', 
    'untagged' = 'Untagged', 
    'tagged/safe' = 'Tagged/Safe', 
    'tagged/unsafe' = 'Tagged/Unsafe') %>% 
  tab_header(title = 'RESA Safety Category vs. Building Inundation') %>% 
  tab_options(heading.background.color = '#d9d9d9', 
              column_labels.background.color = '#f2f2f2')

```

## Plot damages by safety category and by depth-damage relationship

We generated 1,000 realizations of damage for the inundation heights reported by the Sonoma GIS map. 
The results of this process are summarized in Figure 8(b) below. 

```{r results = 'hide'}
## load depth-damage function(s)
source('_scripts/6_DM/DM.R')

## format existing inundation info for f(DM|INUN) function
wet.bldg <- which(buildings$inun > 0)
inundation <- list(matrix(buildings$inun[wet.bldg]))
attributes(inundation)$n.inun <- NA
attributes(inundation)$buildings <-
  st_coordinates(buildings) %>%
  cbind(id = 1:nrow(.), .) %>%
  .[wet.bldg,]
attributes(inundation)$wet.bldg <- wet.bldg

## format depth-damage information
hazus <- hazus %>% 
  filter(Basement == 'Y') %>%
  mutate(depth_m = depth_m + 3/mft) %>%
  group_by(depth_m) %>%
  summarize(damage_min = Min(damage_pct),
            damage_mean = Mean(damage_pct),
            damage_max = Max(damage_pct))
flemo <- flemo %>%
  group_by(depth_m) %>%
  summarize(damage_min = Min(damage_pct),
            damage_mean = Mean(damage_pct),
            damage_max = Max(damage_pct))

## calculate damage using the Wing et al. (2020) relationships
cl <- parallel::makeCluster(num_cores)
registerDoSNOW(cl)
damage.beta <- generate_damage(
  inundation, 
  buildings = buildings %>% st_drop_geometry %>% rename(GEOID = tract),
  foundations = nsi1.base,
  curve = 'beta', 
  hazus = hazus, beta = wing2020,
  probabilistic = TRUE,
  n.damage = 1e3)
damage.beta <- damage.beta[[1]] %>% 
  right_join(buildings %>% st_drop_geometry, ., by = 'bldg')

## calculate damage using the Hazus-MH relationships
damage.hazus <- generate_damage(
  inundation,
  buildings = buildings %>% st_drop_geometry %>% rename(GEOID = tract),
  foundations = nsi1.base,
  curve = 'hazus',
  hazus = hazus, beta = wing2020,
  probabilistic = TRUE,
  n.damage = 1e3)
damage.hazus <- damage.hazus[[1]] %>% 
  right_join(buildings %>% st_drop_geometry, ., by = 'bldg')
stopCluster(cl)

## plot panel 8(b): histograms of damage ratio by safety category 
## and by depth-damage relationship
```

```{r fig8b, echo = FALSE}
## combine damages into one dataframe
num_inun <- buildings %>% 
  st_drop_geometry %>% 
  group_by(safety) %>% 
  summarize(num_inun = Sum(inun>0)) %>% 
  pull(num_inun)
tags <- c(
  paste0('Untagged \n(n = ', num_inun[1], ')'), 
  paste0('Tagged/Safe \n(n = ', num_inun[2], ')'),
  paste0('Tagged/Unsafe \n(n = ', num_inun[3], ')'))
damage <- left_join(
  damage.beta %>% 
    mutate(dm = case_when(is.na(dm) ~ 0, TRUE ~ dm)) %>%
    transmute(bldg, n.damage, dm.beta = dm, safety),
  damage.hazus %>% 
    mutate(dm = case_when(is.na(dm) ~ 0, TRUE ~ dm)) %>%
    transmute(bldg, n.damage, dm.hazus = dm, safety),
  by = c('bldg', 'n.damage', 'safety')) %>% 
  mutate(safety = case_when(
    safety == 'untagged' ~ tags[1],
    safety == 'tagged/safe' ~ tags[2],
    safety == 'tagged/unsafe' ~ tags[3]) %>% 
      factor(levels = tags)) %>% 
  pivot_longer(cols = c(dm.hazus, dm.beta), names_to = 'curve', values_to = 'dm') %>% 
  mutate(curve = case_when(
    curve == 'dm.beta' ~ 'Wing et al.\n', curve == 'dm.hazus' ~ 'Hazus-MH\n'))

g16 <- ggplot(damage) + 
  geom_histogram(
    aes(x = dm, y = ..density.., fill = safety), boundary = 0, bins = 15,
    color = 'black', size = 0.25, show.legend = FALSE) +
  lemon::facet_rep_grid(curve ~ safety, switch = 'y') + 
  scale_fill_manual(breaks = tags, values = roma.colors[3:1]) + 
  scale_x_continuous('Simulated Damage Ratio', 
    limits = c(0,1), expand = expansion(mult = c(0,0)),
    labels = percent_format(accuracy = 1)) + 
  scale_y_origin('Probability of Occurrence \n') + 
  coord_flip(clip = 'off') + 
  theme(strip.background = element_blank(), strip.placement = 'outside',
        panel.spacing.x = unit(0.1, 'lines'), panel.spacing.y = unit(0.1, 'lines'))
if (!publish) g16 

```

```{r fig8, include = publish, echo = FALSE}
plot_grid(
  g13, g16, nrow = 2, 
  labels = c('(a)', '(b)'), label_fontfamily = 'Segoe UI', 
  label_size = 12, label_y = c(0.2, 0.95),
  rel_heights = c(3,5))
ggsave('_figures/fig08_damage.png', width = 8.3, height = 10, units = 'cm')

```

# $f(DV|DM)$

The final component model in the PARRA framework is not directly validated as part of this case study, because we do not have building-level damage data to use as input and we do not have building-level loss data to validate our predictions against. 
Please see the script `lossexceedance.Rmd` for calculations related to the next portion of the paper. 
