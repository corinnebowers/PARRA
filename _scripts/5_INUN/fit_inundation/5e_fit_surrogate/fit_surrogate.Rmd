---
title: "fit_surrogate"
output:
  html_document:
    toc: true 
    toc_float: true
    #toc_depth: 3  
    code_folding: hide
    number_sections: true 
    theme: spacelab   #https://www.datadreaming.org/post/r-markdown-theme-gallery/
    highlight: tango  #https://www.garrickadenbuie.com/blog/pandoc-syntax-highlighting-examples/
---

```{r setup, include = FALSE}
## setup
knitr::opts_knit$set(root.dir = 'D:/1-PARRA/')
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
knitr::opts_chunk$set(fig.show = 'hold', fig.align = 'center')
rm(list = ls())

```

```{r}
## setup information
source('_data/setup.R')
source('_data/plots.R')

## load required packages
require(plotly)

## load location information
load('_data/lisflood/dem.Rdata')
load('_data/aoi/aoi.Rdata')
load('_data/NHD/NHD.Rdata')

## load nonzero cells
load('_data/nonzero/nonzero.Rdata')

```

```{r echo = FALSE}
## should figures be saved out for the publication?
publish <- FALSE

if (!publish) {
  theme_set(
    theme_classic() + theme(
      text = element_text(family = 'Segoe UI', size = 12),
      axis.line = element_line(size = 0.5),
      axis.ticks = element_line(size = 0.5, color = 'black'),
      legend.key.size = unit(0.5, 'cm')))
  }

```

# Set up best-fit parameter optimization problem

## Define the surrogate model

<!-- We have chosen to use the inverse distance weighted (IDW) spatial interpolation method.  -->
We used the inverse distance weighting (IDW) spatial interpolation method to generate inundation maps within the Monte Carlo process and reduce the computational demand of the PARRA framework. 
The IDW surrogate model is described by the three equations below.

$$ \mathrm{M}^* = \frac{\sum\limits_{i=1}^n \lambda_i \mathrm{M}_i} {\sum\limits_{i=1}^n \lambda_i}$$

$$ \lambda_i = \lVert \mathrm{\textbf{x}}^*, \mathrm{\textbf{x}}_i \rVert ^{-p} $$

$$ \mathrm{\textbf{x}} = \left\{ \alpha\!*\!z_{Q_p}, \; (1-\alpha)\!*\!z_{t_p} \right\} $$

$\mathrm{M}^*$ in the first equation represents the unknown (target) inundation map we are trying to predict. 
We calculate this map as the weighted sum of the $n$ closest maps. 
A map $\mathrm{M}_i$ is defined as "close" if its hydrograph parameters $\left\{Q_p, t_p \right\}_i$  are similar to the target hydrograph parameters $\left\{Q_p, t_p \right\}^*$.  

$Q_p^*$ and $t_p^*$ are known values used as inputs to the IDW interpolator function. 
However, they are not Euclidean coordinates, so $\mathrm{\textbf{x}}^*$ in the third equation is the coordinate vector that represents $\left\{Q_p, t_p \right\}^*$ in modified parameter space, after applying a normal score transformation and an anisotropy correction factor $\alpha$. 
We calculate the L2 (Euclidean) distance between $\mathrm{\textbf{x}}^*$, the coordinate vector of the target map, and $\mathrm{\textbf{x}}_i$, the coordinate vector of the $i^{th}$ closest map. 
The inverse of this distance multiplied by the power function $p$ is the calculated weight $\lambda_i$ for map $\mathrm{M}_i$, as shown in the second equation.

## Define hyperparameters

The IDW method has three hyperparameters to tune, which are as follows:

* $n$ defines the size of the search neighborhood;
* $p$ is the power function coefficient, which defines the decay rate of the distance weighting; and
* $\alpha$ defines the anisotropy (asymmetry of information content) between $Q_p$ and $t_p$.


## Define error metric

We generate a bank of LISFLOOD models for various combinations of $Q_p$ and $t_p$. 
We then find the best-fit hyperparameters by performing 10-fold cross-validation on Sherlock, Stanford's high-performance computing cluster.
Within each fold of the 10-fold cross-validation, 10\% of the data is withheld for testing.
The surrogate model predicts the unseen data, and the error metric is some measurement of the difference between the observed vs. predicted inundation map. 
The goal of the cross-validation is to find the set of hyperparameters that minimizes the error. 

A cell-by-cell comparison of inundation predictions at every 40 m $times$ 40 m cell in the study area is computationally intractable.
Therefore we calculate aggregate error across the study area domain in two ways.
The RMSE (root mean squared error) is a common error metric used in machine learning and parameter tuning. 
It is attractive because it includes all data points while also penalizing larger error values. 
The MAE (mean absolute error) is a less common but more intuitive metric that weights all error values equally and measures how far your predictions were off, on average, from the true value.
We then repeat this calculation two times: once on the cells that experience inundation at least 1\% of the time (10 of the pre-computed LISFLOOD maps) and once on the cells that experience inundation at least 50\% of the time. 
This is to focus in on the locations of the study area that contribute the most to severe flood damage and flood impacts.
The extent of the study area inundation 1\% of the time vs. 50\% of the time is shown in the figure below.

```{r}
## plot 1% inundation area vs. 50% inundation area
ggplot(raster.df(nonzero)) + 
  geom_sf(data = sonoma %>% st_union %>% st_crop(aoi), 
          color = 'black', fill = 'grey95') + 
  # geom_sf(data = aoi, fill = NA) + 
  geom_raster(data = raster.df(nonzero) %>% filter(value >= 10),
              aes(x=x, y=y, fill = '1% Inundation Area')) + 
  geom_raster(data = raster.df(nonzero) %>% filter(value >= 500),
              aes(x=x, y=y, fill = '50% Inundation Area')) +
  scale_fill_manual('', values = c('grey70', 'grey30')) + 
  geom_sf(data = russian %>% st_crop(aoi)) + 
  theme_void() + theme(legend.position = 'bottom')

```

Overall this gives us four error metrics to consider.
However, these metrics are just to move from a full map to a single summary number. 
The results of the Sherlock computing give us 1,000 values for each combination of $n$, $p$, and $\alpha$, one for every pre-computed map. 
This is shown in the histogram below for a single hyperparameter combination. 
Therefore we aggregate our error metrics even further.

```{r}
## load error data
files <- paste0('_scripts/5_INUN/fit_inundation/5e_fit_surrogate/results/error', 1:10, '.csv')
error <- foreach(file = files) %do% {
  read_csv(file)} %>%
  do.call(rbind, .)

const01 <- (error$SRSS01/error$RMSE01)[1]
const50 <- (error$SRSS50/error$RMSE50)[1]
error <- error %>% 
  mutate(MAE01 = MAE01/const01^2, MAE50 = MAE50/const50^2)

```

```{r}
## plot error histogram for one hyperparameter combination
error %>% 
  filter(n == 5 & p == 1 & alpha == 0.6) %>% 
  arrange(desc(RMSE50)) %>% 
  # .[-(1:100),] %>% 
  ggplot() + 
  geom_density(aes(x = MAE01, color = 'MAE01'), size = 1) + 
  geom_density(aes(x = RMSE01, color = 'RMSE01'), size = 1) + 
  geom_density(aes(x = MAE50, color = 'MAE50'), size = 1) + 
  geom_density(aes(x = RMSE50, color = 'RMSE50'), size = 1) + 
  scale_color_manual('Error Metric', values = roma.colors[-3]) + 
  scale_x_origin() + scale_y_origin() + 
  coord_cartesian(xlim = c(0,0.5)) + 
  theme(legend.position = c(0.8, 0.8))

```

# Calculate best-fit IDW parameter values

Rather than the rigorous parameter fit process we conducted for the LISFLOOD environmental parameters in **5a_fit_lisflood**, this is more of a qualitative assessment. 
Using the interactive plotly tool in R, we iteratively removed values of $n$, $p$, and $\alpha$ that led to unfavorable error outcomes. 
A few iterations are shown below for demonstration purposes.

```{r}
g1 <- ggplot(error) + 
  geom_point(aes(x = MAE01, y = MAE50), color = 'grey40', alpha = 0.01) + 
  scale_x_origin() + scale_y_origin() + 
  geom_parity() + coord_fixed()
g2 <- ggplot(error) + 
  geom_point(aes(x = RMSE01, y = RMSE50), color = 'grey40', alpha = 0.01) + 
  scale_x_origin() + scale_y_origin() + 
  geom_parity() + coord_fixed()
plot_grid(g1, g2, nrow = 1)
ggsave('C:/Users/cbowers/Desktop/error1.png')

g3 <- ggplot(error) + 
  geom_point(aes(x = MAE01, y = RMSE01), color = 'grey40', alpha = 0.01) + 
  scale_x_origin() + scale_y_origin() + 
  geom_parity() + coord_fixed()
g4 <- ggplot(error) + 
  geom_point(aes(x = MAE50, y = RMSE50), color = 'grey40', alpha = 0.01) + 
  scale_x_origin() + scale_y_origin() + 
  geom_parity() + coord_fixed()
plot_grid(g3, g4, nrow = 1)
ggsave('C:/Users/cbowers/Desktop/error2.png')

```

```{r}
error.npalpha <- error %>% 
  group_by(n, p, alpha) %>% 
  summarize(
    MAE01.mean = mean(MAE01), MAE50.mean = mean(MAE50),
    MAE01.05 = quantile(MAE01, 0.05), MAE01.95 = quantile(MAE01, 0.95),
    MAE50.05 = quantile(MAE50, 0.05), MAE50.95 = quantile(MAE50, 0.95),
    RMSE01.rms = sqrt(mean(RMSE01^2)), RMSE50.rms = sqrt(mean(RMSE50^2)),
    # RMSE01.mean = mean(RMSE01), RMSE50.mean = mean(RMSE50),
    RMSE01.05 = quantile(RMSE01, 0.05), RMSE01.95 = quantile(RMSE01, 0.95),
    RMSE50.05 = quantile(RMSE50, 0.05), RMSE50.95 = quantile(RMSE50, 0.95)) %>% 
  ungroup

require(GGally)
error.npalpha %>% 
  select(starts_with('MAE')) %>% 
  ggpairs
error.npalpha %>% 
  select(starts_with('RMSE')) %>% 
  # select(-ends_with('mean')) %>% 
  ggpairs

error.npalpha %>% 
  select(contains('01')) %>% 
  ggpairs
error.npalpha %>% 
  select(contains('50')) %>% 
  ggpairs

error.npalpha %>% 
  select(starts_with('RMSE')) %>% 
  select(ends_with('rms'), ends_with('05'), ends_with('95')) %>% 
  ggpairs
error.npalpha %>% 
  select(starts_with('RMSE')) %>% 
  select(ends_with('05'), ends_with('95'), ends_with('rms')) %>% 
  ggpairs
error.npalpha %>% 
  select(starts_with('RMSE')) %>% 
  select(ends_with('95'), ends_with('rms'), ends_with('05')) %>% 
  ggpairs

error.npalpha %>% 
  select('RMSE50.rms', 'RMSE01.05', 'RMSE01.95') %>% 
  ggpairs

```

```{r}
n.best <- c()
p.best <- c()
alpha.best <- c()

```

```{r}
## balance MAE01.mean & RMSE50.rms

error.subset <- error.npalpha %>% 
  filter(alpha > 0.25 & alpha < 0.85) %>% 
  filter(n > 3 & n < 20) %>% 
  filter(p > 0.75 & p < 4) %>% 
  filter(alpha > 0.35 & alpha < 0.75) %>% 
  filter(n < 10) %>% 
  filter(p > 1.5) %>% 
  filter(n > 4 & alpha > 0.45)
nrow(error.subset)/nrow(error.npalpha)

plot_ly(
  data = error.subset,
  x = ~MAE01.mean, y = ~RMSE50.rms, color = ~factor(n),
  colors = scico(n = length(unique(error.subset$n)), palette = 'roma'))
plot_ly(
  data = error.subset,
  x = ~MAE01.mean, y = ~RMSE50.rms, color = ~factor(p),
  colors = scico(n = length(unique(error.subset$p)), palette = 'roma'))
plot_ly(
  data = error.subset,
  x = ~MAE01.mean, y = ~RMSE50.rms, color = ~factor(alpha),
  colors = scico(n = length(unique(error.subset$alpha)), palette = 'roma'))
  
n.best <- c(n.best, unique(error.subset$n))
p.best <- c(p.best, unique(error.subset$p))
alpha.best <- c(alpha.best, unique(error.subset$alpha))

```

```{r}
## balance MAE50.mean & RMSE01.rms

error.subset <- error.npalpha %>% 
  filter(alpha > 0.3 & alpha < 0.75) %>% 
  filter(n > 3 & n < 12) %>% 
  filter(p > 1 & p < 4) %>% 
  filter(alpha > 0.45 & alpha < 0.7) %>% 
  filter(n > 4 & n < 10) %>% 
  filter(p > 1.5 & alpha > 0.5)
nrow(error.subset)/nrow(error.npalpha)

plot_ly(
  data = error.subset,
  x = ~MAE50.mean, y = ~RMSE01.rms, color = ~factor(n),
  colors = scico(n = length(unique(error.subset$n)), palette = 'roma'))
plot_ly(
  data = error.subset,
  x = ~MAE50.mean, y = ~RMSE01.rms, color = ~factor(p),
  colors = scico(n = length(unique(error.subset$p)), palette = 'roma'))
plot_ly(
  data = error.subset,
  x = ~MAE50.mean, y = ~RMSE01.rms, color = ~factor(alpha),
  colors = scico(n = length(unique(error.subset$alpha)), palette = 'roma'))

n.best <- c(n.best, unique(error.subset$n))
p.best <- c(p.best, unique(error.subset$p))
alpha.best <- c(alpha.best, unique(error.subset$alpha))

```

```{r}
## balance RMSE01.95 & RMSE50.05

error.subset <- error.npalpha %>% 
  filter(n > 2 & n < 15) %>% 
  filter(p < 4) %>% 
  filter(alpha > 0.35 & alpha < 0.75) %>% 
  filter(p > 0.5) %>% 
  filter(n > 3 & n < 12) %>% 
  filter(alpha > 0.45 & alpha < 0.7) %>% 
  filter(p > 1) %>% 
  filter(n > 4 & n < 10) %>% 
  filter(alpha > 0.5)
nrow(error.subset)/nrow(error.npalpha)

plot_ly(
  data = error.subset,
  x = ~RMSE01.95, y = ~RMSE50.05, color = ~factor(n),
  colors = scico(n = length(unique(error.subset$n)), palette = 'roma'))
plot_ly(
  data = error.subset,
  x = ~RMSE01.95, y = ~RMSE50.05, color = ~factor(p),
  colors = scico(n = length(unique(error.subset$p)), palette = 'roma'))
plot_ly(
  data = error.subset,
  x = ~RMSE01.95, y = ~RMSE50.05, color = ~factor(alpha),
  colors = scico(n = length(unique(error.subset$alpha)), palette = 'roma'))

n.best <- c(n.best, unique(error.subset$n))
p.best <- c(p.best, unique(error.subset$p))
alpha.best <- c(alpha.best, unique(error.subset$alpha))

```

```{r}
## balance MAE01.95 & MAE50.05

error.subset <- error.npalpha %>% 
  filter(alpha > 0.35 & alpha < 0.85) %>% 
  filter(n > 1 & n < 10) %>% 
  filter(p > 1 & p < 4) %>% 
  filter(alpha > 0.5 & alpha < 0.8) %>% 
  filter(n > 4) %>% 
  filter(alpha > 0.55 & alpha < 0.75) %>% 
  filter(n < 8) %>% 
  filter(p < 3)
nrow(error.subset)/nrow(error.npalpha)

plot_ly(
  data = error.subset,
  x = ~MAE01.95, y = ~MAE50.05, color = ~factor(n),
  colors = scico(n = length(unique(error.subset$n)), palette = 'roma'))
plot_ly(
  data = error.subset,
  x = ~MAE01.95, y = ~MAE50.05, color = ~factor(p),
  colors = scico(n = length(unique(error.subset$p)), palette = 'roma'))
plot_ly(
  data = error.subset,
  x = ~MAE01.95, y = ~MAE50.05, color = ~factor(alpha),
  colors = scico(n = length(unique(error.subset$alpha)), palette = 'roma'))

n.best <- c(n.best, unique(error.subset$n))
p.best <- c(p.best, unique(error.subset$p))
alpha.best <- c(alpha.best, unique(error.subset$alpha))

```

```{r}
n.best <- sort(unique(n.best))
p.best <- sort(unique(p.best))
alpha.best <- sort(unique(alpha.best))

error.best <- error.npalpha %>% 
  filter(n %in% n.best & p %in% p.best & alpha %in% alpha.best)

error.best %>% 
  select(-n, -p, -alpha) %>% 
  apply(2, function(x) x/max(x)) %>% 
  apply(1, sum) %>% 
  cbind(error.best %>% select(n, p, alpha), error.total = .) %>% 
  arrange(error.total)

error.best %>% 
  select(-n, -p, -alpha) %>% 
  apply(2, function(x) x/max(x)) %>% 
  as.data.frame %>% 
  mutate(central = select(., ends_with('mean'), ends_with('rms')) %>% apply(1, sum),
         extreme = select(., ends_with('05'), ends_with('95')) %>% apply(1, sum)) %>% 
  transmute(error.weighted = central*2/3 + extreme/3) %>% 
  cbind(error.best %>% select(n, p, alpha), .) %>% 
  arrange(error.weighted)

n = 6
p = 2.5
alpha = 0.6

```

